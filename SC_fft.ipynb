{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (2027, 1) target: (2027, 2)\n",
      "input: (225, 1) target: (225, 2)\n"
     ]
    }
   ],
   "source": [
    "def read_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    input_data = []\n",
    "    target_data = []\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if i % 2 == 0:  # Input data (rows 1, 3, 5, 7, ...)\n",
    "            input_data.append(float(line.strip()))\n",
    "        else:          # Target data (rows 2, 4, 6, 8, ...)\n",
    "            target_data.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "    # Convert to NumPy arrays and reshape\n",
    "    input_array = np.array(input_data).reshape(-1, 1)\n",
    "    target_array = np.array(target_data).reshape(-1, 2)\n",
    "    \n",
    "    return input_array, target_array\n",
    "\n",
    "def min_max_normalize(data, data_min=None, data_max=None):\n",
    "    if data_min is None:\n",
    "        data_min = np.min(data, axis=0)\n",
    "    if data_max is None:\n",
    "        data_max = np.max(data, axis=0)\n",
    "    return (data - data_min) / (data_max - data_min), data_min, data_max\n",
    "\n",
    "train_in, train_target = read_data('fftdata5/aggregated_train.txt')\n",
    "print(\"input:\", train_in.shape, \"target:\", train_target.shape)\n",
    "train_in = torch.from_numpy(train_in).float()\n",
    "train_target = torch.from_numpy(train_target).float()\n",
    "\n",
    "test_in, test_target = read_data('fftdata5/aggregated_test.txt')\n",
    "print(\"input:\", test_in.shape, \"target:\", test_target.shape)\n",
    "test_in = torch.from_numpy(test_in).float()\n",
    "test_target = torch.from_numpy(test_target).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data min:  0.0 max:  1.0 shape:  (500, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the parameters of the signal\n",
    "N = 1000  # number of sample points\n",
    "T = 1.0 / 1000.0  # sample spacing\n",
    "x = np.linspace(0.0, N*T, N, endpoint=False)\n",
    "\n",
    "# Generate a sine wave signal with amplitude less than 1\n",
    "y = 0.5 * np.sin(2.0 * np.pi * x) + 0.25 * np.sin(4.0 * np.pi * x)\n",
    "\n",
    "# Compute the DFT of the signal\n",
    "yf = np.fft.fft(y)\n",
    "\n",
    "# Compute the corresponding frequencies\n",
    "xf = np.fft.fftfreq(N, T)[:N//2]\n",
    "\n",
    "# Now, let's create the input and target data\n",
    "input_data = xf.reshape(-1, 1)\n",
    "target_data = np.stack((np.abs(yf[:N//2].real), np.abs(yf[:N//2].imag)), axis=-1)\n",
    "\n",
    "# normalize the input data and target data in rage [0, 1]\n",
    "input_data = (input_data - np.min(input_data)) / (np.max(input_data) - np.min(input_data))\n",
    "target_data = (target_data - np.min(target_data)) / (np.max(target_data) - np.min(target_data))\n",
    "\n",
    "# check the min and max of input_data and target_data\n",
    "print('input_data min: ', np.min(input_data), 'max: ', np.max(input_data), 'shape: ', input_data.shape)\n",
    "\n",
    "# split train and test data use traintetst split, then make them to torch tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_in, test_in, train_target, test_target = train_test_split(input_data, target_data, test_size=0.1, random_state=42)\n",
    "train_in, test_in = torch.from_numpy(train_in).float(), torch.from_numpy(test_in).float()\n",
    "train_target, test_target = torch.from_numpy(train_target).float(), torch.from_numpy(test_target).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clamp -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at epoch:  0 test_loss:  0.3514707088470459\n",
      "saved model at epoch:  1 test_loss:  0.32352688908576965\n",
      "saved model at epoch:  2 test_loss:  0.31682127714157104\n",
      "saved model at epoch:  3 test_loss:  0.3063015937805176\n",
      "saved model at epoch:  4 test_loss:  0.29004767537117004\n",
      "saved model at epoch:  5 test_loss:  0.2653801739215851\n",
      "saved model at epoch:  6 test_loss:  0.2294348180294037\n",
      "saved model at epoch:  7 test_loss:  0.18161407113075256\n",
      "saved model at epoch:  8 test_loss:  0.13233450055122375\n",
      "saved model at epoch:  9 test_loss:  0.09806369245052338\n",
      "saved model at epoch:  10 test_loss:  0.08126118034124374\n",
      "saved model at epoch:  11 test_loss:  0.07129648327827454\n",
      "saved model at epoch:  12 test_loss:  0.06704793870449066\n",
      "saved model at epoch:  13 test_loss:  0.06515732407569885\n",
      "saved model at epoch:  14 test_loss:  0.0642089769244194\n",
      "saved model at epoch:  15 test_loss:  0.06351149082183838\n",
      "saved model at epoch:  16 test_loss:  0.06301552057266235\n",
      "saved model at epoch:  17 test_loss:  0.06267134100198746\n",
      "saved model at epoch:  18 test_loss:  0.06242946535348892\n",
      "saved model at epoch:  19 test_loss:  0.06224632263183594\n",
      "saved model at epoch:  20 test_loss:  0.062088385224342346\n",
      "saved model at epoch:  21 test_loss:  0.06193196773529053\n",
      "saved model at epoch:  22 test_loss:  0.061759091913700104\n",
      "saved model at epoch:  23 test_loss:  0.0615525059401989\n",
      "saved model at epoch:  24 test_loss:  0.06131071597337723\n",
      "saved model at epoch:  25 test_loss:  0.06103146821260452\n",
      "saved model at epoch:  26 test_loss:  0.06071465089917183\n",
      "saved model at epoch:  27 test_loss:  0.060354795306921005\n",
      "saved model at epoch:  28 test_loss:  0.059943825006484985\n",
      "saved model at epoch:  29 test_loss:  0.05947057530283928\n",
      "saved model at epoch:  30 test_loss:  0.058920327574014664\n",
      "saved model at epoch:  31 test_loss:  0.058320820331573486\n",
      "saved model at epoch:  32 test_loss:  0.05767752602696419\n",
      "saved model at epoch:  33 test_loss:  0.056907784193754196\n",
      "saved model at epoch:  34 test_loss:  0.055970121175050735\n",
      "saved model at epoch:  35 test_loss:  0.0548115074634552\n",
      "saved model at epoch:  36 test_loss:  0.053617238998413086\n",
      "saved model at epoch:  37 test_loss:  0.052722781896591187\n",
      "saved model at epoch:  38 test_loss:  0.051805250346660614\n",
      "saved model at epoch:  39 test_loss:  0.05121174827218056\n",
      "saved model at epoch:  40 test_loss:  0.05054236948490143\n",
      "saved model at epoch:  41 test_loss:  0.04976531118154526\n",
      "saved model at epoch:  42 test_loss:  0.04887741804122925\n",
      "saved model at epoch:  43 test_loss:  0.04781673103570938\n",
      "saved model at epoch:  44 test_loss:  0.04653896391391754\n",
      "saved model at epoch:  45 test_loss:  0.04515673220157623\n",
      "saved model at epoch:  46 test_loss:  0.04387909173965454\n",
      "saved model at epoch:  47 test_loss:  0.0426444485783577\n",
      "saved model at epoch:  48 test_loss:  0.04138381406664848\n",
      "saved model at epoch:  49 test_loss:  0.040085308253765106\n",
      "saved model at epoch:  50 test_loss:  0.03872991353273392\n",
      "saved model at epoch:  51 test_loss:  0.03754405677318573\n",
      "saved model at epoch:  52 test_loss:  0.03672310337424278\n",
      "saved model at epoch:  53 test_loss:  0.035907160490751266\n",
      "saved model at epoch:  54 test_loss:  0.0350683219730854\n",
      "saved model at epoch:  55 test_loss:  0.03419702500104904\n",
      "saved model at epoch:  56 test_loss:  0.03357822075486183\n",
      "saved model at epoch:  57 test_loss:  0.03308292105793953\n",
      "saved model at epoch:  58 test_loss:  0.03254939988255501\n",
      "saved model at epoch:  59 test_loss:  0.0319305956363678\n",
      "saved model at epoch:  60 test_loss:  0.03117465414106846\n",
      "saved model at epoch:  61 test_loss:  0.030225394293665886\n",
      "saved model at epoch:  62 test_loss:  0.029051389545202255\n",
      "saved model at epoch:  63 test_loss:  0.028034133836627007\n",
      "saved model at epoch:  64 test_loss:  0.027470866218209267\n",
      "saved model at epoch:  65 test_loss:  0.027181316167116165\n",
      "saved model at epoch:  66 test_loss:  0.026915786787867546\n",
      "saved model at epoch:  67 test_loss:  0.026672404259443283\n",
      "saved model at epoch:  68 test_loss:  0.02644571289420128\n",
      "saved model at epoch:  69 test_loss:  0.026232058182358742\n",
      "saved model at epoch:  70 test_loss:  0.026028843596577644\n",
      "saved model at epoch:  71 test_loss:  0.02583414874970913\n",
      "saved model at epoch:  72 test_loss:  0.02564649097621441\n",
      "saved model at epoch:  73 test_loss:  0.025472644716501236\n",
      "saved model at epoch:  74 test_loss:  0.02530822344124317\n",
      "saved model at epoch:  75 test_loss:  0.02514643780887127\n",
      "saved model at epoch:  76 test_loss:  0.024986933916807175\n",
      "saved model at epoch:  77 test_loss:  0.02482871524989605\n",
      "saved model at epoch:  78 test_loss:  0.024670898914337158\n",
      "saved model at epoch:  79 test_loss:  0.02451280876994133\n",
      "saved model at epoch:  80 test_loss:  0.02435384877026081\n",
      "saved model at epoch:  81 test_loss:  0.024193579331040382\n",
      "saved model at epoch:  82 test_loss:  0.02403159625828266\n",
      "saved model at epoch:  83 test_loss:  0.023867560550570488\n",
      "saved model at epoch:  84 test_loss:  0.02370116300880909\n",
      "saved model at epoch:  85 test_loss:  0.023532157763838768\n",
      "saved model at epoch:  86 test_loss:  0.023360328748822212\n",
      "saved model at epoch:  87 test_loss:  0.02318546362221241\n",
      "saved model at epoch:  88 test_loss:  0.02300741709768772\n",
      "saved model at epoch:  89 test_loss:  0.022826047614216805\n",
      "saved model at epoch:  90 test_loss:  0.022657610476017\n",
      "saved model at epoch:  91 test_loss:  0.022557856515049934\n",
      "saved model at epoch:  92 test_loss:  0.022459233179688454\n",
      "saved model at epoch:  93 test_loss:  0.0223655067384243\n",
      "saved model at epoch:  94 test_loss:  0.022276215255260468\n",
      "saved model at epoch:  95 test_loss:  0.022191034629940987\n",
      "saved model at epoch:  96 test_loss:  0.022109637036919594\n",
      "saved model at epoch:  97 test_loss:  0.022031737491488457\n",
      "saved model at epoch:  98 test_loss:  0.02195705845952034\n",
      "saved model at epoch:  99 test_loss:  0.02188534289598465\n",
      "saved model at epoch:  100 test_loss:  0.021816344931721687\n",
      "saved model at epoch:  101 test_loss:  0.02174982987344265\n",
      "saved model at epoch:  102 test_loss:  0.021685605868697166\n",
      "saved model at epoch:  103 test_loss:  0.02162056788802147\n",
      "saved model at epoch:  104 test_loss:  0.02155696600675583\n",
      "saved model at epoch:  105 test_loss:  0.021504705771803856\n",
      "saved model at epoch:  106 test_loss:  0.021454758942127228\n",
      "saved model at epoch:  107 test_loss:  0.021406421437859535\n",
      "saved model at epoch:  108 test_loss:  0.021359309554100037\n",
      "saved model at epoch:  109 test_loss:  0.02131316065788269\n",
      "saved model at epoch:  110 test_loss:  0.021267767995595932\n",
      "saved model at epoch:  111 test_loss:  0.021222993731498718\n",
      "saved model at epoch:  112 test_loss:  0.0211787112057209\n",
      "saved model at epoch:  113 test_loss:  0.021134812384843826\n",
      "saved model at epoch:  114 test_loss:  0.021091213449835777\n",
      "saved model at epoch:  115 test_loss:  0.021047836169600487\n",
      "saved model at epoch:  116 test_loss:  0.021004587411880493\n",
      "saved model at epoch:  117 test_loss:  0.02096140943467617\n",
      "saved model at epoch:  118 test_loss:  0.020918242633342743\n",
      "saved model at epoch:  119 test_loss:  0.020875025540590286\n",
      "saved model at epoch:  120 test_loss:  0.020831706002354622\n",
      "saved model at epoch:  121 test_loss:  0.020788226276636124\n",
      "saved model at epoch:  122 test_loss:  0.02074454165995121\n",
      "saved model at epoch:  123 test_loss:  0.020700620487332344\n",
      "saved model at epoch:  124 test_loss:  0.020656390115618706\n",
      "saved model at epoch:  125 test_loss:  0.02061183750629425\n",
      "saved model at epoch:  126 test_loss:  0.0205669105052948\n",
      "saved model at epoch:  127 test_loss:  0.02052156627178192\n",
      "saved model at epoch:  128 test_loss:  0.020475776866078377\n",
      "saved model at epoch:  129 test_loss:  0.020429514348506927\n",
      "saved model at epoch:  130 test_loss:  0.02038273960351944\n",
      "saved model at epoch:  131 test_loss:  0.020335419103503227\n",
      "saved model at epoch:  132 test_loss:  0.020287519320845604\n",
      "saved model at epoch:  133 test_loss:  0.020239029079675674\n",
      "saved model at epoch:  134 test_loss:  0.020189881324768066\n",
      "saved model at epoch:  135 test_loss:  0.020140059292316437\n",
      "saved model at epoch:  136 test_loss:  0.020089546218514442\n",
      "saved model at epoch:  137 test_loss:  0.02003830298781395\n",
      "saved model at epoch:  138 test_loss:  0.01998629979789257\n",
      "saved model at epoch:  139 test_loss:  0.01993352174758911\n",
      "saved model at epoch:  140 test_loss:  0.01987992227077484\n",
      "saved model at epoch:  141 test_loss:  0.019825493916869164\n",
      "saved model at epoch:  142 test_loss:  0.01977020688354969\n",
      "saved model at epoch:  143 test_loss:  0.01971401832997799\n",
      "saved model at epoch:  144 test_loss:  0.019656891003251076\n",
      "saved model at epoch:  145 test_loss:  0.019598808139562607\n",
      "saved model at epoch:  146 test_loss:  0.019539725035429\n",
      "saved model at epoch:  147 test_loss:  0.019479619339108467\n",
      "saved model at epoch:  148 test_loss:  0.01941842958331108\n",
      "saved model at epoch:  149 test_loss:  0.019356122240424156\n",
      "saved model at epoch:  150 test_loss:  0.01929260417819023\n",
      "saved model at epoch:  151 test_loss:  0.0192264374345541\n",
      "saved model at epoch:  152 test_loss:  0.019151965156197548\n",
      "saved model at epoch:  153 test_loss:  0.019061053171753883\n",
      "saved model at epoch:  154 test_loss:  0.018941828981041908\n",
      "saved model at epoch:  155 test_loss:  0.018774328753352165\n",
      "saved model at epoch:  156 test_loss:  0.01851818896830082\n",
      "saved model at epoch:  157 test_loss:  0.01808198355138302\n",
      "saved model at epoch:  158 test_loss:  0.017278390005230904\n",
      "saved model at epoch:  159 test_loss:  0.01586792804300785\n",
      "saved model at epoch:  160 test_loss:  0.01394600234925747\n",
      "saved model at epoch:  161 test_loss:  0.012158588506281376\n",
      "saved model at epoch:  162 test_loss:  0.01050017960369587\n",
      "saved model at epoch:  163 test_loss:  0.00896538607776165\n",
      "saved model at epoch:  164 test_loss:  0.007583751808851957\n",
      "saved model at epoch:  165 test_loss:  0.006419790908694267\n",
      "saved model at epoch:  166 test_loss:  0.005488119088113308\n",
      "saved model at epoch:  167 test_loss:  0.004761110059916973\n",
      "saved model at epoch:  168 test_loss:  0.004254644270986319\n",
      "saved model at epoch:  169 test_loss:  0.003904902609065175\n",
      "saved model at epoch:  170 test_loss:  0.003626040183007717\n",
      "saved model at epoch:  171 test_loss:  0.0034819182474166155\n",
      "saved model at epoch:  172 test_loss:  0.0033819014206528664\n",
      "saved model at epoch:  173 test_loss:  0.003304234938696027\n",
      "saved model at epoch:  174 test_loss:  0.0032395145390182734\n",
      "saved model at epoch:  175 test_loss:  0.0031832477543503046\n",
      "saved model at epoch:  176 test_loss:  0.0031330641359090805\n",
      "saved model at epoch:  177 test_loss:  0.0030875513330101967\n",
      "saved model at epoch:  178 test_loss:  0.0030458003748208284\n",
      "saved model at epoch:  179 test_loss:  0.0030071926303207874\n",
      "saved model at epoch:  180 test_loss:  0.0029712668620049953\n",
      "saved model at epoch:  181 test_loss:  0.002937686163932085\n",
      "saved model at epoch:  182 test_loss:  0.002906179055571556\n",
      "saved model at epoch:  183 test_loss:  0.002876552054658532\n",
      "saved model at epoch:  184 test_loss:  0.0028486191295087337\n",
      "saved model at epoch:  185 test_loss:  0.002822242211550474\n",
      "saved model at epoch:  186 test_loss:  0.0027972909156233072\n",
      "saved model at epoch:  187 test_loss:  0.002773650921881199\n",
      "saved model at epoch:  188 test_loss:  0.002751237014308572\n",
      "saved model at epoch:  189 test_loss:  0.00272996723651886\n",
      "saved model at epoch:  190 test_loss:  0.002709747524932027\n",
      "saved model at epoch:  191 test_loss:  0.0026905157137662172\n",
      "saved model at epoch:  192 test_loss:  0.002672189148142934\n",
      "saved model at epoch:  193 test_loss:  0.002654704265296459\n",
      "saved model at epoch:  194 test_loss:  0.0026380049530416727\n",
      "saved model at epoch:  195 test_loss:  0.0026220425497740507\n",
      "saved model at epoch:  196 test_loss:  0.0026067786384373903\n",
      "saved model at epoch:  197 test_loss:  0.002592165255919099\n",
      "saved model at epoch:  198 test_loss:  0.002578168176114559\n",
      "saved model at epoch:  199 test_loss:  0.0025647496804594994\n",
      "saved model at epoch:  200 test_loss:  0.002551872283220291\n",
      "saved model at epoch:  201 test_loss:  0.0025395071133971214\n",
      "saved model at epoch:  202 test_loss:  0.0025276062078773975\n",
      "saved model at epoch:  203 test_loss:  0.0025161458179354668\n",
      "saved model at epoch:  204 test_loss:  0.0025051040574908257\n",
      "saved model at epoch:  205 test_loss:  0.0024944646283984184\n",
      "saved model at epoch:  206 test_loss:  0.002484194003045559\n",
      "saved model at epoch:  207 test_loss:  0.0024742749519646168\n",
      "saved model at epoch:  208 test_loss:  0.00246469397097826\n",
      "saved model at epoch:  209 test_loss:  0.0024554398842155933\n",
      "saved model at epoch:  210 test_loss:  0.0024464819580316544\n",
      "saved model at epoch:  211 test_loss:  0.0024378288071602583\n",
      "saved model at epoch:  212 test_loss:  0.0024294499307870865\n",
      "saved model at epoch:  213 test_loss:  0.0024213348515331745\n",
      "saved model at epoch:  214 test_loss:  0.0024134828709065914\n",
      "saved model at epoch:  215 test_loss:  0.002405876526609063\n",
      "saved model at epoch:  216 test_loss:  0.0023984999861568213\n",
      "saved model at epoch:  217 test_loss:  0.002391352318227291\n",
      "saved model at epoch:  218 test_loss:  0.0023844235111027956\n",
      "saved model at epoch:  219 test_loss:  0.0023777023889124393\n",
      "saved model at epoch:  220 test_loss:  0.0023711840622127056\n",
      "saved model at epoch:  221 test_loss:  0.0023648675996810198\n",
      "saved model at epoch:  222 test_loss:  0.0023587322793900967\n",
      "saved model at epoch:  223 test_loss:  0.0023527787998318672\n",
      "saved model at epoch:  224 test_loss:  0.002346991328522563\n",
      "saved model at epoch:  225 test_loss:  0.0023413747549057007\n",
      "saved model at epoch:  226 test_loss:  0.0023359123151749372\n",
      "saved model at epoch:  227 test_loss:  0.0023306142538785934\n",
      "saved model at epoch:  228 test_loss:  0.002325467299669981\n",
      "saved model at epoch:  229 test_loss:  0.002320465398952365\n",
      "saved model at epoch:  230 test_loss:  0.0023155997041612864\n",
      "saved model at epoch:  231 test_loss:  0.0023108655586838722\n",
      "saved model at epoch:  232 test_loss:  0.002306269481778145\n",
      "saved model at epoch:  233 test_loss:  0.002301794243976474\n",
      "saved model at epoch:  234 test_loss:  0.002297446131706238\n",
      "saved model at epoch:  235 test_loss:  0.002293207449838519\n",
      "saved model at epoch:  236 test_loss:  0.002289088210090995\n",
      "saved model at epoch:  237 test_loss:  0.002285076305270195\n",
      "saved model at epoch:  238 test_loss:  0.00228118896484375\n",
      "saved model at epoch:  239 test_loss:  0.002277402440086007\n",
      "saved model at epoch:  240 test_loss:  0.0022737167309969664\n",
      "saved model at epoch:  241 test_loss:  0.0022701220586895943\n",
      "saved model at epoch:  242 test_loss:  0.0022666193544864655\n",
      "saved model at epoch:  243 test_loss:  0.0022632109466940165\n",
      "saved model at epoch:  244 test_loss:  0.0022598830983042717\n",
      "saved model at epoch:  245 test_loss:  0.002256640698760748\n",
      "saved model at epoch:  246 test_loss:  0.0022534828167408705\n",
      "saved model at epoch:  247 test_loss:  0.0022504059597849846\n",
      "saved model at epoch:  248 test_loss:  0.0022474031429737806\n",
      "saved model at epoch:  249 test_loss:  0.0022444857750087976\n",
      "saved model at epoch:  250 test_loss:  0.0022416291758418083\n",
      "saved model at epoch:  251 test_loss:  0.002238845219835639\n",
      "saved model at epoch:  252 test_loss:  0.002236125757917762\n",
      "saved model at epoch:  253 test_loss:  0.002233474049717188\n",
      "saved model at epoch:  254 test_loss:  0.0022308845072984695\n",
      "saved model at epoch:  255 test_loss:  0.0022283545695245266\n",
      "saved model at epoch:  256 test_loss:  0.0022258833050727844\n",
      "saved model at epoch:  257 test_loss:  0.0022234702482819557\n",
      "saved model at epoch:  258 test_loss:  0.0022211133036762476\n",
      "saved model at epoch:  259 test_loss:  0.002218810375779867\n",
      "saved model at epoch:  260 test_loss:  0.002216560300439596\n",
      "saved model at epoch:  261 test_loss:  0.0022143612150102854\n",
      "saved model at epoch:  262 test_loss:  0.002212212886661291\n",
      "saved model at epoch:  263 test_loss:  0.002210108330473304\n",
      "saved model at epoch:  291 test_loss:  0.002210104139521718\n",
      "saved model at epoch:  292 test_loss:  0.0022100782953202724\n",
      "saved model at epoch:  293 test_loss:  0.002210052218288183\n",
      "saved model at epoch:  294 test_loss:  0.002210025442764163\n",
      "saved model at epoch:  295 test_loss:  0.002209997735917568\n",
      "saved model at epoch:  296 test_loss:  0.002209973521530628\n",
      "saved model at epoch:  297 test_loss:  0.002209952799603343\n",
      "saved model at epoch:  298 test_loss:  0.0022099241614341736\n",
      "saved model at epoch:  299 test_loss:  0.0022099025081843138\n",
      "saved model at epoch:  300 test_loss:  0.0022098778281360865\n",
      "saved model at epoch:  301 test_loss:  0.0022098503541201353\n",
      "saved model at epoch:  302 test_loss:  0.002209829166531563\n",
      "saved model at epoch:  303 test_loss:  0.0022098063491284847\n",
      "saved model at epoch:  304 test_loss:  0.002209780737757683\n",
      "saved model at epoch:  305 test_loss:  0.002209759782999754\n",
      "saved model at epoch:  306 test_loss:  0.0022097371984273195\n",
      "saved model at epoch:  307 test_loss:  0.002209713915362954\n",
      "saved model at epoch:  308 test_loss:  0.002209689700976014\n",
      "saved model at epoch:  309 test_loss:  0.0022096687462180853\n",
      "saved model at epoch:  310 test_loss:  0.002209647325798869\n",
      "saved model at epoch:  311 test_loss:  0.002209628466516733\n",
      "saved model at epoch:  312 test_loss:  0.002209607046097517\n",
      "saved model at epoch:  313 test_loss:  0.002209586324170232\n",
      "saved model at epoch:  314 test_loss:  0.0022095656022429466\n",
      "saved model at epoch:  315 test_loss:  0.0022095474414527416\n",
      "saved model at epoch:  316 test_loss:  0.002209523692727089\n",
      "saved model at epoch:  317 test_loss:  0.0022095039021223783\n",
      "saved model at epoch:  318 test_loss:  0.002209487371146679\n",
      "saved model at epoch:  319 test_loss:  0.0022094680462032557\n",
      "saved model at epoch:  320 test_loss:  0.0022094491869211197\n",
      "saved model at epoch:  321 test_loss:  0.002209430793300271\n",
      "saved model at epoch:  322 test_loss:  0.002209410769864917\n",
      "saved model at epoch:  323 test_loss:  0.0022093933075666428\n",
      "saved model at epoch:  324 test_loss:  0.002209374215453863\n",
      "saved model at epoch:  325 test_loss:  0.002209354192018509\n",
      "saved model at epoch:  326 test_loss:  0.002209339989349246\n",
      "saved model at epoch:  327 test_loss:  0.002209324622526765\n",
      "saved model at epoch:  328 test_loss:  0.002209305763244629\n",
      "saved model at epoch:  329 test_loss:  0.0022092899307608604\n",
      "saved model at epoch:  330 test_loss:  0.002209270605817437\n",
      "saved model at epoch:  331 test_loss:  0.0022092568688094616\n",
      "saved model at epoch:  332 test_loss:  0.002209240337833762\n",
      "saved model at epoch:  333 test_loss:  0.002209227532148361\n",
      "saved model at epoch:  334 test_loss:  0.0022092058788985014\n",
      "saved model at epoch:  335 test_loss:  0.0022091958671808243\n",
      "saved model at epoch:  336 test_loss:  0.002209180034697056\n",
      "saved model at epoch:  337 test_loss:  0.002209166530519724\n",
      "saved model at epoch:  338 test_loss:  0.0022091486025601625\n",
      "saved model at epoch:  339 test_loss:  0.002209135564044118\n",
      "saved model at epoch:  340 test_loss:  0.0022091211285442114\n",
      "saved model at epoch:  341 test_loss:  0.002209109254181385\n",
      "saved model at epoch:  342 test_loss:  0.0022090920247137547\n",
      "saved model at epoch:  343 test_loss:  0.0022090813145041466\n",
      "saved model at epoch:  344 test_loss:  0.002209066180512309\n",
      "saved model at epoch:  345 test_loss:  0.0022090543061494827\n",
      "saved model at epoch:  346 test_loss:  0.002209038008004427\n",
      "saved model at epoch:  347 test_loss:  0.002209031255915761\n",
      "saved model at epoch:  348 test_loss:  0.0022090161219239235\n",
      "saved model at epoch:  349 test_loss:  0.0022090051788836718\n",
      "saved model at epoch:  350 test_loss:  0.0022089930716902018\n",
      "saved model at epoch:  351 test_loss:  0.0022089830599725246\n",
      "saved model at epoch:  352 test_loss:  0.0022089709527790546\n",
      "saved model at epoch:  353 test_loss:  0.002208960009738803\n",
      "saved model at epoch:  354 test_loss:  0.002208947902545333\n",
      "saved model at epoch:  355 test_loss:  0.002208935096859932\n",
      "saved model at epoch:  356 test_loss:  0.002208924852311611\n",
      "saved model at epoch:  357 test_loss:  0.002208911580964923\n",
      "saved model at epoch:  358 test_loss:  0.0022089022677391768\n",
      "saved model at epoch:  359 test_loss:  0.002208892721682787\n",
      "saved model at epoch:  360 test_loss:  0.0022088815458118916\n",
      "saved model at epoch:  361 test_loss:  0.0022088736295700073\n",
      "saved model at epoch:  362 test_loss:  0.002208863152191043\n",
      "saved model at epoch:  363 test_loss:  0.002208851743489504\n",
      "saved model at epoch:  364 test_loss:  0.0022088398691266775\n",
      "saved model at epoch:  365 test_loss:  0.0022088331170380116\n",
      "saved model at epoch:  366 test_loss:  0.002208821475505829\n",
      "saved model at epoch:  367 test_loss:  0.002208813326433301\n",
      "saved model at epoch:  368 test_loss:  0.0022088049445301294\n",
      "saved model at epoch:  369 test_loss:  0.0022087974939495325\n",
      "saved model at epoch:  370 test_loss:  0.0022087872494012117\n",
      "saved model at epoch:  371 test_loss:  0.00220877630636096\n",
      "saved model at epoch:  372 test_loss:  0.0022087704855948687\n",
      "saved model at epoch:  373 test_loss:  0.0022087593097239733\n",
      "saved model at epoch:  374 test_loss:  0.002208755351603031\n",
      "saved model at epoch:  375 test_loss:  0.00220874254591763\n",
      "saved model at epoch:  376 test_loss:  0.002208735328167677\n",
      "saved model at epoch:  377 test_loss:  0.0022087281104177237\n",
      "saved model at epoch:  378 test_loss:  0.0022087208926677704\n",
      "saved model at epoch:  379 test_loss:  0.002208712976425886\n",
      "saved model at epoch:  380 test_loss:  0.002208706457167864\n",
      "saved model at epoch:  381 test_loss:  0.0022086978424340487\n",
      "saved model at epoch:  382 test_loss:  0.0022086927201598883\n",
      "saved model at epoch:  383 test_loss:  0.0022086836397647858\n",
      "saved model at epoch:  384 test_loss:  0.0022086738608777523\n",
      "saved model at epoch:  385 test_loss:  0.002208669437095523\n",
      "saved model at epoch:  386 test_loss:  0.002208662685006857\n",
      "saved model at epoch:  387 test_loss:  0.0022086543031036854\n",
      "saved model at epoch:  388 test_loss:  0.002208646619692445\n",
      "saved model at epoch:  389 test_loss:  0.0022086401004344225\n",
      "saved model at epoch:  390 test_loss:  0.0022086328826844692\n",
      "saved model at epoch:  391 test_loss:  0.002208628226071596\n",
      "saved model at epoch:  392 test_loss:  0.002208622172474861\n",
      "saved model at epoch:  393 test_loss:  0.002208616118878126\n",
      "saved model at epoch:  394 test_loss:  0.002208610065281391\n",
      "saved model at epoch:  395 test_loss:  0.002208600752055645\n",
      "saved model at epoch:  396 test_loss:  0.0022085942327976227\n",
      "saved model at epoch:  397 test_loss:  0.0022085884120315313\n",
      "saved model at epoch:  398 test_loss:  0.0022085867822170258\n",
      "saved model at epoch:  399 test_loss:  0.0022085763048380613\n",
      "saved model at epoch:  400 test_loss:  0.0022085714153945446\n",
      "saved model at epoch:  401 test_loss:  0.0022085653617978096\n",
      "saved model at epoch:  402 test_loss:  0.002208561869338155\n",
      "saved model at epoch:  403 test_loss:  0.0022085583768785\n",
      "saved model at epoch:  404 test_loss:  0.002208548365160823\n",
      "saved model at epoch:  405 test_loss:  0.002208546968176961\n",
      "saved model at epoch:  406 test_loss:  0.002208540914580226\n",
      "saved model at epoch:  407 test_loss:  0.0022085371892899275\n",
      "saved model at epoch:  408 test_loss:  0.002208526711910963\n",
      "saved model at epoch:  410 test_loss:  0.002208518097177148\n",
      "saved model at epoch:  411 test_loss:  0.002208516001701355\n",
      "saved model at epoch:  412 test_loss:  0.0022085115779191256\n",
      "saved model at epoch:  413 test_loss:  0.002208505989983678\n",
      "saved model at epoch:  414 test_loss:  0.0022085027303546667\n",
      "saved model at epoch:  415 test_loss:  0.0022084955126047134\n",
      "saved model at epoch:  416 test_loss:  0.002208490390330553\n",
      "saved model at epoch:  417 test_loss:  0.002208487829193473\n",
      "saved model at epoch:  418 test_loss:  0.002208483638241887\n",
      "saved model at epoch:  419 test_loss:  0.002208481077104807\n",
      "saved model at epoch:  420 test_loss:  0.00220847618766129\n",
      "saved model at epoch:  421 test_loss:  0.002208470832556486\n",
      "saved model at epoch:  422 test_loss:  0.0022084666416049004\n",
      "saved model at epoch:  423 test_loss:  0.0022084617521613836\n",
      "saved model at epoch:  424 test_loss:  0.0022084563970565796\n",
      "saved model at epoch:  425 test_loss:  0.002208451274782419\n",
      "saved model at epoch:  426 test_loss:  0.002208450110629201\n",
      "saved model at epoch:  427 test_loss:  0.002208445221185684\n",
      "saved model at epoch:  428 test_loss:  0.0022084389347583055\n",
      "saved model at epoch:  429 test_loss:  0.002208433113992214\n",
      "saved model at epoch:  430 test_loss:  0.002208431949838996\n",
      "saved model at epoch:  431 test_loss:  0.0022084293887019157\n",
      "saved model at epoch:  432 test_loss:  0.002208426594734192\n",
      "saved model at epoch:  433 test_loss:  0.002208423800766468\n",
      "saved model at epoch:  434 test_loss:  0.0022084189113229513\n",
      "saved model at epoch:  435 test_loss:  0.0022084161173552275\n",
      "saved model at epoch:  436 test_loss:  0.002208412392064929\n",
      "saved model at epoch:  437 test_loss:  0.002208409132435918\n",
      "saved model at epoch:  438 test_loss:  0.0022084044758230448\n",
      "saved model at epoch:  439 test_loss:  0.0022084014490246773\n",
      "saved model at epoch:  440 test_loss:  0.0022083960939198732\n",
      "saved model at epoch:  441 test_loss:  0.0022083939984440804\n",
      "saved model at epoch:  442 test_loss:  0.002208390273153782\n",
      "saved model at epoch:  443 test_loss:  0.002208388177677989\n",
      "saved model at epoch:  444 test_loss:  0.0022083865478634834\n",
      "saved model at epoch:  445 test_loss:  0.0022083823569118977\n",
      "saved model at epoch:  446 test_loss:  0.002208380727097392\n",
      "saved model at epoch:  447 test_loss:  0.002208378864452243\n",
      "saved model at epoch:  448 test_loss:  0.002208373975008726\n",
      "saved model at epoch:  449 test_loss:  0.0022083716467022896\n",
      "saved model at epoch:  450 test_loss:  0.002208367455750704\n",
      "saved model at epoch:  451 test_loss:  0.002208363264799118\n",
      "saved model at epoch:  452 test_loss:  0.0022083630319684744\n",
      "saved model at epoch:  453 test_loss:  0.002208361169323325\n",
      "saved model at epoch:  454 test_loss:  0.0022083537187427282\n",
      "saved model at epoch:  455 test_loss:  0.002208353253081441\n",
      "saved model at epoch:  456 test_loss:  0.0022083502262830734\n",
      "saved model at epoch:  457 test_loss:  0.002208349294960499\n",
      "saved model at epoch:  458 test_loss:  0.0022083476651459932\n",
      "saved model at epoch:  459 test_loss:  0.002208345802500844\n",
      "saved model at epoch:  460 test_loss:  0.002208343241363764\n",
      "saved model at epoch:  461 test_loss:  0.0022083388175815344\n",
      "saved model at epoch:  462 test_loss:  0.002208335092291236\n",
      "saved model at epoch:  464 test_loss:  0.0022083325311541557\n",
      "saved model at epoch:  465 test_loss:  0.0022083318326622248\n",
      "saved model at epoch:  466 test_loss:  0.0022083260118961334\n",
      "saved model at epoch:  467 test_loss:  0.0022083234507590532\n",
      "saved model at epoch:  468 test_loss:  0.002208319026976824\n",
      "saved model at epoch:  469 test_loss:  0.002208318095654249\n",
      "saved model at epoch:  471 test_loss:  0.002208314836025238\n",
      "saved model at epoch:  472 test_loss:  0.0022083139047026634\n",
      "saved model at epoch:  473 test_loss:  0.002208312042057514\n",
      "saved model at epoch:  474 test_loss:  0.0022083092480897903\n",
      "saved model at epoch:  476 test_loss:  0.0022083052899688482\n",
      "saved model at epoch:  477 test_loss:  0.0022083017975091934\n",
      "saved model at epoch:  478 test_loss:  0.002208299934864044\n",
      "saved model at epoch:  479 test_loss:  0.002208296675235033\n",
      "saved model at epoch:  480 test_loss:  0.00220829457975924\n",
      "saved model at epoch:  481 test_loss:  0.0022082908544689417\n",
      "saved model at epoch:  484 test_loss:  0.0022082889918237925\n",
      "saved model at epoch:  485 test_loss:  0.0022082864306867123\n",
      "saved model at epoch:  487 test_loss:  0.002208284568041563\n",
      "saved model at epoch:  488 test_loss:  0.0022082836367189884\n",
      "saved model at epoch:  489 test_loss:  0.002208280609920621\n",
      "saved model at epoch:  490 test_loss:  0.0022082803770899773\n",
      "saved model at epoch:  491 test_loss:  0.002208277815952897\n",
      "saved model at epoch:  492 test_loss:  0.0022082768846303225\n",
      "saved model at epoch:  493 test_loss:  0.0022082740906625986\n",
      "saved model at epoch:  494 test_loss:  0.0022082722280174494\n",
      "saved model at epoch:  495 test_loss:  0.002208270598202944\n",
      "saved model at epoch:  497 test_loss:  0.0022082673385739326\n",
      "saved model at epoch:  498 test_loss:  0.0022082661744207144\n",
      "saved model at epoch:  499 test_loss:  0.002208264311775565\n",
      "saved model at epoch:  500 test_loss:  0.002208262449130416\n",
      "saved model at epoch:  502 test_loss:  0.0022082580253481865\n",
      "saved model at epoch:  504 test_loss:  0.0022082561627030373\n",
      "saved model at epoch:  505 test_loss:  0.0022082538343966007\n",
      "saved model at epoch:  506 test_loss:  0.002208253601565957\n",
      "saved model at epoch:  507 test_loss:  0.0022082519717514515\n",
      "saved model at epoch:  508 test_loss:  0.002208251738920808\n",
      "saved model at epoch:  509 test_loss:  0.002208249643445015\n",
      "saved model at epoch:  510 test_loss:  0.0022082470823079348\n",
      "saved model at epoch:  511 test_loss:  0.00220824358984828\n",
      "saved model at epoch:  512 test_loss:  0.0022082431241869926\n",
      "saved model at epoch:  513 test_loss:  0.0022082426585257053\n",
      "saved model at epoch:  514 test_loss:  0.0022082417272031307\n",
      "saved model at epoch:  515 test_loss:  0.0022082380019128323\n",
      "saved model at epoch:  517 test_loss:  0.0022082373034209013\n",
      "saved model at epoch:  519 test_loss:  0.002208233578130603\n",
      "saved model at epoch:  520 test_loss:  0.0022082310169935226\n",
      "saved model at epoch:  522 test_loss:  0.002208230784162879\n",
      "saved model at epoch:  523 test_loss:  0.0022082284558564425\n",
      "saved model at epoch:  524 test_loss:  0.0022082277573645115\n",
      "saved model at epoch:  527 test_loss:  0.0022082258947193623\n",
      "saved model at epoch:  529 test_loss:  0.0022082235664129257\n",
      "saved model at epoch:  530 test_loss:  0.0022082205396145582\n",
      "saved model at epoch:  531 test_loss:  0.002208220073953271\n",
      "saved model at epoch:  534 test_loss:  0.0022082182113081217\n",
      "saved model at epoch:  536 test_loss:  0.0022082163486629725\n",
      "saved model at epoch:  537 test_loss:  0.002208215883001685\n",
      "saved model at epoch:  538 test_loss:  0.002208214020356536\n",
      "saved model at epoch:  539 test_loss:  0.0022082121577113867\n",
      "saved model at epoch:  541 test_loss:  0.002208211924880743\n",
      "saved model at epoch:  543 test_loss:  0.002208209130913019\n",
      "saved model at epoch:  544 test_loss:  0.0022082084324210882\n",
      "saved model at epoch:  546 test_loss:  0.002208206569775939\n",
      "saved model at epoch:  548 test_loss:  0.002208203775808215\n",
      "saved model at epoch:  550 test_loss:  0.002208203310146928\n",
      "saved model at epoch:  552 test_loss:  0.0022082007490098476\n",
      "saved model at epoch:  553 test_loss:  0.002208200516179204\n",
      "saved model at epoch:  556 test_loss:  0.0022082002833485603\n",
      "saved model at epoch:  557 test_loss:  0.0022081974893808365\n",
      "saved model at epoch:  558 test_loss:  0.002208196558058262\n",
      "saved model at epoch:  559 test_loss:  0.0022081956267356873\n",
      "saved model at epoch:  560 test_loss:  0.002208192367106676\n",
      "saved model at epoch:  566 test_loss:  0.0022081921342760324\n",
      "saved model at epoch:  567 test_loss:  0.002208191202953458\n",
      "saved model at epoch:  569 test_loss:  0.0022081888746470213\n",
      "saved model at epoch:  572 test_loss:  0.0022081886418163776\n",
      "saved model at epoch:  573 test_loss:  0.0022081874776631594\n",
      "saved model at epoch:  574 test_loss:  0.0022081867791712284\n",
      "saved model at epoch:  577 test_loss:  0.0022081846836954355\n",
      "saved model at epoch:  579 test_loss:  0.0022081814240664244\n",
      "saved model at epoch:  583 test_loss:  0.002208178862929344\n",
      "saved model at epoch:  587 test_loss:  0.002208178164437413\n",
      "saved model at epoch:  588 test_loss:  0.0022081744391471148\n",
      "saved model at epoch:  594 test_loss:  0.00220817350782454\n",
      "saved model at epoch:  596 test_loss:  0.0022081718780100346\n",
      "saved model at epoch:  600 test_loss:  0.0022081697825342417\n",
      "saved model at epoch:  607 test_loss:  0.002208168152719736\n",
      "saved model at epoch:  610 test_loss:  0.002208166988566518\n",
      "saved model at epoch:  611 test_loss:  0.002208166755735874\n",
      "saved model at epoch:  613 test_loss:  0.0022081651259213686\n",
      "saved model at epoch:  615 test_loss:  0.0022081644274294376\n",
      "saved model at epoch:  622 test_loss:  0.0022081611678004265\n",
      "saved model at epoch:  623 test_loss:  0.002208158141002059\n",
      "saved model at epoch:  628 test_loss:  0.0022081562783569098\n",
      "saved model at epoch:  632 test_loss:  0.002208156045526266\n",
      "saved model at epoch:  634 test_loss:  0.0022081551142036915\n",
      "saved model at epoch:  639 test_loss:  0.0022081537172198296\n",
      "saved model at epoch:  645 test_loss:  0.002208152087405324\n",
      "saved model at epoch:  650 test_loss:  0.0022081509232521057\n",
      "saved model at epoch:  656 test_loss:  0.0022081471979618073\n",
      "saved model at epoch:  660 test_loss:  0.0022081469651311636\n",
      "saved model at epoch:  662 test_loss:  0.002208146033808589\n",
      "saved model at epoch:  663 test_loss:  0.0022081458009779453\n",
      "saved model at epoch:  666 test_loss:  0.0022081441711634398\n",
      "saved model at epoch:  667 test_loss:  0.002208142541348934\n",
      "saved model at epoch:  673 test_loss:  0.0022081423085182905\n",
      "saved model at epoch:  691 test_loss:  0.002208141377195716\n",
      "saved model at epoch:  694 test_loss:  0.002208140678703785\n",
      "saved model at epoch:  697 test_loss:  0.0022081390488892794\n",
      "saved model at epoch:  708 test_loss:  0.0022081369534134865\n",
      "saved model at epoch:  730 test_loss:  0.0022081348579376936\n",
      "saved model at epoch:  733 test_loss:  0.002208133228123188\n",
      "saved model at epoch:  744 test_loss:  0.0022081329952925444\n",
      "saved model at epoch:  753 test_loss:  0.0022081302013248205\n",
      "saved model at epoch:  765 test_loss:  0.002208129735663533\n",
      "saved model at epoch:  779 test_loss:  0.002208129270002246\n",
      "saved model at epoch:  782 test_loss:  0.002208127873018384\n",
      "saved model at epoch:  796 test_loss:  0.0022081276401877403\n",
      "saved model at epoch:  798 test_loss:  0.002208124380558729\n",
      "saved model at epoch:  855 test_loss:  0.002208123914897442\n",
      "saved model at epoch:  857 test_loss:  0.0022081234492361546\n",
      "saved model at epoch:  869 test_loss:  0.0022081227507442236\n",
      "saved model at epoch:  873 test_loss:  0.0022081213537603617\n",
      "saved model at epoch:  999 test_loss:  0.0022081208880990744\n"
     ]
    }
   ],
   "source": [
    "# create a NN, all FCs, 1 input, 2 output, layer nodes is (1,4,4,2), using tanh() as activation function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def calculate_error(orig_lines, nn_lines):\n",
    "    # python version of average relative error between two sets of complex numbers\n",
    "    abs_error = 0\n",
    "    for i in range(len(orig_lines)):\n",
    "        orig_real, orig_imag = orig_lines[i]\n",
    "        nn_real, nn_imag = nn_lines[i]\n",
    "\n",
    "        diff_real = orig_real - nn_real\n",
    "        diff_imag = orig_imag - nn_imag\n",
    "\n",
    "        nominator = math.sqrt(diff_real * diff_real + diff_imag * diff_imag)\n",
    "        denominator = math.sqrt(orig_real * orig_real + orig_imag * orig_imag)\n",
    "\n",
    "        if denominator == 0 or math.isnan(nominator) or math.isnan(denominator):\n",
    "            e = 1.0\n",
    "        else:\n",
    "            e = min(nominator / denominator, 1.0)\n",
    "\n",
    "        abs_error += e\n",
    "\n",
    "    return abs_error / float(len(orig_lines))\n",
    "\n",
    "class dianet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dianet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 2)\n",
    "        self.fc2 = nn.Linear(2, 3)\n",
    "        self.fc3 = nn.Linear(3, 4)\n",
    "        self.fc4 = nn.Linear(4, 3)\n",
    "        self.fc5 = nn.Linear(3, 2)\n",
    "\n",
    "        self.msk2 = np.array([[1,0],[1,1],[0,1]])\n",
    "        self.msk3 = np.array([[1,0,0],[1,1,0],[0,1,1],[0,0,1]])\n",
    "        self.msk4 = np.array([[1,1,0,0],[0,1,1,0],[0,0,1,1]])\n",
    "        self.msk5 = np.array([[1,1,0],[0,1,1]])\n",
    "\n",
    "    def forward(self, x, dwn=-1, up=1):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data, dwn, up)\n",
    "        self.fc1.bias.data = torch.clamp(self.fc1.bias.data, dwn, up)\n",
    "        x1 = torch.tanh(self.fc1(x))\n",
    "        # x1 = F.leaky_relu(self.fc1(x), negative_slope=0.125)\n",
    "\n",
    "        self.fc2.weight.data *= torch.from_numpy(self.msk2).float()\n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data, dwn, up)\n",
    "        self.fc2.bias.data = torch.clamp(self.fc2.bias.data, dwn, up)\n",
    "        x2 = torch.tanh(self.fc2(x1))\n",
    "        # x2 = F.leaky_relu(self.fc2(x1), negative_slope=0.125)\n",
    "\n",
    "        self.fc3.weight.data *= torch.from_numpy(self.msk3).float()\n",
    "        self.fc3.weight.data = torch.clamp(self.fc3.weight.data, dwn, up)\n",
    "        self.fc3.bias.data = torch.clamp(self.fc3.bias.data, dwn, up)\n",
    "        x3 = torch.tanh(self.fc3(x2))\n",
    "        x3c = torch.cat((x3[:,0:1], x3[:,1:-1]+x1, x3[:,-1:]), 1) # (n, 4)\n",
    "\n",
    "        self.fc4.weight.data *= torch.from_numpy(self.msk4).float()\n",
    "        self.fc4.weight.data = torch.clamp(self.fc4.weight.data, dwn, up)\n",
    "        self.fc4.bias.data = torch.clamp(self.fc4.bias.data, dwn, up)\n",
    "        x4 = torch.tanh(self.fc4(x3c))\n",
    "        x4c = x4 + x2 # (n, 3)\n",
    "\n",
    "        self.fc5.weight.data *= torch.from_numpy(self.msk5).float()\n",
    "        self.fc5.weight.data = torch.clamp(self.fc5.weight.data, dwn, up)\n",
    "        self.fc5.bias.data = torch.clamp(self.fc5.bias.data, dwn, up)\n",
    "        x5 = self.fc5(x4c)\n",
    "        x5c = x5 + x3[:,1:-1] # (n, 2)\n",
    "\n",
    "        return x5c\n",
    "\n",
    "# train the NN\n",
    "import torch.optim as optim\n",
    "\n",
    "# model = baseline() # test_loss 0.0001585180580150336; error:  0.015001012789398081\n",
    "model = dianet() # test_loss 0.001; error:  0.0401\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "minloss = 999\n",
    "for epoch in range(1000):\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    batchsize = 16\n",
    "    for i in range(0, len(train_in), batchsize):\n",
    "        optimizer.zero_grad()\n",
    "        input = train_in[i:i+batchsize]\n",
    "        tar = train_target[i:i+batchsize]\n",
    "        output = model(input, -1, 1)\n",
    "        loss = loss_fn(output, tar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        count += 1\n",
    "    epoch_loss /= count\n",
    "    \n",
    "    # test the model\n",
    "    model.eval()\n",
    "    test_output = model(test_in, -1, 1)\n",
    "    test_loss = loss_fn(test_output, test_target).item()\n",
    "    if test_loss < minloss:\n",
    "        minloss = test_loss\n",
    "        torch.save(model.state_dict(), 'fftdata5/dianet-11.pt')\n",
    "        print('saved model at epoch: ', epoch, 'test_loss: ', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss 0.0022081208880990744\n",
      "error:  0.060688020657458604\n"
     ]
    }
   ],
   "source": [
    "def calculate_error_rate(test_output, test_target):\n",
    "    # Calculate the absolute error\n",
    "    absolute_error = np.abs(test_output - test_target)\n",
    "\n",
    "    # Calculate the mean absolute percentage error\n",
    "    mape = np.mean(absolute_error / np.abs(test_target)) * 100\n",
    "\n",
    "    return mape\n",
    "\n",
    "model = dianet()\n",
    "model.load_state_dict(torch.load('fftdata5/dianet-11.pt'))\n",
    "model.eval()\n",
    "test_output = model(test_in)\n",
    "test_loss = loss_fn(test_output, test_target).item()\n",
    "print('test_loss', test_loss)\n",
    "\n",
    "test_output_np = test_output.detach().numpy()\n",
    "test_target_np = test_target.detach().numpy()\n",
    "\n",
    "err = calculate_error(test_target_np, test_output_np)\n",
    "print('error: ', err)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clamp 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at epoch 0 epoch_loss 0.41202271382013955\n",
      "saved at epoch 1 epoch_loss 0.3917871614297231\n",
      "saved at epoch 2 epoch_loss 0.3767745872338613\n",
      "saved at epoch 3 epoch_loss 0.3647073984146118\n",
      "saved at epoch 4 epoch_loss 0.3548909107844035\n",
      "saved at epoch 5 epoch_loss 0.3468308349450429\n",
      "saved at epoch 6 epoch_loss 0.34014036059379577\n",
      "saved at epoch 7 epoch_loss 0.3345129152139028\n",
      "saved at epoch 8 epoch_loss 0.32970499992370605\n",
      "saved at epoch 9 epoch_loss 0.32552324334780375\n",
      "saved at epoch 10 epoch_loss 0.32181506355603534\n",
      "saved at epoch 11 epoch_loss 0.3184611439704895\n",
      "saved at epoch 12 epoch_loss 0.3153696109851201\n",
      "saved at epoch 13 epoch_loss 0.31247095863024393\n",
      "saved at epoch 14 epoch_loss 0.30971385836601256\n",
      "saved at epoch 15 epoch_loss 0.3070603092511495\n",
      "saved at epoch 16 epoch_loss 0.3044837127129237\n",
      "saved at epoch 17 epoch_loss 0.30196021298567455\n",
      "saved at epoch 18 epoch_loss 0.29946885307629906\n",
      "saved at epoch 19 epoch_loss 0.297007617354393\n",
      "saved at epoch 20 epoch_loss 0.2945692191521327\n",
      "saved at epoch 21 epoch_loss 0.29214932918548586\n",
      "saved at epoch 22 epoch_loss 0.28974556426207226\n",
      "saved at epoch 23 epoch_loss 0.2873569558064143\n",
      "saved at epoch 24 epoch_loss 0.28498321771621704\n",
      "saved at epoch 25 epoch_loss 0.28262462516625725\n",
      "saved at epoch 26 epoch_loss 0.28028163909912107\n",
      "saved at epoch 27 epoch_loss 0.2779548853635788\n",
      "saved at epoch 28 epoch_loss 0.27564496199289956\n",
      "saved at epoch 29 epoch_loss 0.2742713818947474\n",
      "saved at epoch 30 epoch_loss 0.2741956820090612\n",
      "saved at epoch 31 epoch_loss 0.27415694693724313\n",
      "saved at epoch 32 epoch_loss 0.27413918972015383\n",
      "saved at epoch 33 epoch_loss 0.2741325110197067\n",
      "saved at epoch 34 epoch_loss 0.2741313417752584\n",
      "test_loss: MSE:  0.13126787543296814\n",
      "error:  0.681894136462896\n"
     ]
    }
   ],
   "source": [
    "# create a NN, all FCs, 1 input, 2 output, layer nodes is (1,4,4,2), using tanh() as activation function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def calculate_error(orig_lines, nn_lines):\n",
    "    abs_error = 0\n",
    "    for i in range(len(orig_lines)):\n",
    "        orig_real, orig_imag = orig_lines[i]\n",
    "        nn_real, nn_imag = nn_lines[i]\n",
    "\n",
    "        diff_real = orig_real - nn_real\n",
    "        diff_imag = orig_imag - nn_imag\n",
    "\n",
    "        nominator = math.sqrt(diff_real * diff_real + diff_imag * diff_imag)\n",
    "        denominator = math.sqrt(orig_real * orig_real + orig_imag * orig_imag)\n",
    "\n",
    "        if denominator == 0 or math.isnan(nominator) or math.isnan(denominator):\n",
    "            e = 1.0\n",
    "        else:\n",
    "            e = min(nominator / denominator, 1.0)\n",
    "\n",
    "        abs_error += e\n",
    "\n",
    "    return abs_error / float(len(orig_lines))\n",
    "\n",
    "class dianet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dianet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 2)\n",
    "        self.fc2 = nn.Linear(2, 3)\n",
    "        self.fc3 = nn.Linear(3, 2)\n",
    "\n",
    "        self.msk2 = np.array([[1,0],[1,1],[0,1]])\n",
    "        self.msk3 = np.array([[1,1,0],[0,1,1]])\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data, 0, 1)\n",
    "        self.fc1.bias.data = torch.clamp(self.fc1.bias.data, 0, 1)\n",
    "        x1 = torch.tanh(self.fc1(x))\n",
    "        # x1 = F.leaky_relu(self.fc1(x), negative_slope=0.125)\n",
    "\n",
    "        self.fc2.weight.data *= torch.from_numpy(self.msk2).float()\n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data, 0, 1)\n",
    "        self.fc2.bias.data = torch.clamp(self.fc2.bias.data, 0, 1)\n",
    "        x2 = torch.tanh(self.fc2(x1))\n",
    "        # x2 = F.leaky_relu(self.fc2(x1), negative_slope=0.125)\n",
    "\n",
    "        self.fc3.weight.data *= torch.from_numpy(self.msk3).float()\n",
    "        self.fc3.weight.data = torch.clamp(self.fc3.weight.data, 0, 1)\n",
    "        self.fc3.bias.data = torch.clamp(self.fc3.bias.data, 0, 1)\n",
    "        x3 = self.fc3(x2)\n",
    "        x3 = x3+x1\n",
    "\n",
    "        return x3\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# model = baseline() # test_loss 0.0001585180580150336; error:  0.015001012789398081\n",
    "model = dianet() # test_loss 0.001; error:  0.0401\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "minloss = 999\n",
    "for epoch in range(1000):\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    batchsize = 16\n",
    "    for i in range(0, len(train_in), batchsize):\n",
    "        optimizer.zero_grad()\n",
    "        input = train_in[i:i+batchsize]\n",
    "        tar = train_target[i:i+batchsize]\n",
    "        output = model(input)\n",
    "        loss1 = loss_fn(output[:,0:1], tar[:,0:1])\n",
    "        loss2 = loss_fn(output[:,1:2], tar[:,1:2])\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        count += 1\n",
    "    epoch_loss /= count\n",
    "    \n",
    "    if epoch_loss < minloss:\n",
    "        minloss = epoch_loss\n",
    "        torch.save(model.state_dict(), 'fftdata4/dianet_0_1.pth')\n",
    "        print('saved at epoch', epoch, 'epoch_loss', epoch_loss)\n",
    "\n",
    "# test using test_in and test_target\n",
    "model.load_state_dict(torch.load('fftdata4/dianet_0_1.pth'))\n",
    "model.eval()\n",
    "test_pred = model(test_in)\n",
    "test_loss = loss_fn(test_pred, test_target)\n",
    "print('test_loss: MSE: ', test_loss.item())\n",
    "# calculate error\n",
    "test_pred = test_pred.detach().numpy()\n",
    "test_target = test_target.detach().numpy()\n",
    "print('error: ', calculate_error(test_target, test_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at epoch:  0 test_loss:  0.41120296716690063\n",
      "saved model at epoch:  1 test_loss:  0.3376537263393402\n",
      "saved model at epoch:  2 test_loss:  0.33518171310424805\n",
      "saved model at epoch:  3 test_loss:  0.33127909898757935\n",
      "saved model at epoch:  4 test_loss:  0.32454174757003784\n",
      "saved model at epoch:  5 test_loss:  0.3117678165435791\n",
      "saved model at epoch:  6 test_loss:  0.28475257754325867\n",
      "saved model at epoch:  7 test_loss:  0.2257520854473114\n",
      "saved model at epoch:  8 test_loss:  0.12550994753837585\n",
      "saved model at epoch:  9 test_loss:  0.06142571195960045\n",
      "saved model at epoch:  10 test_loss:  0.056578174233436584\n",
      "saved model at epoch:  11 test_loss:  0.05590280145406723\n",
      "saved model at epoch:  12 test_loss:  0.055302608758211136\n",
      "saved model at epoch:  13 test_loss:  0.054705724120140076\n",
      "saved model at epoch:  14 test_loss:  0.05407021567225456\n",
      "saved model at epoch:  15 test_loss:  0.05337583273649216\n",
      "saved model at epoch:  16 test_loss:  0.052610401064157486\n",
      "saved model at epoch:  17 test_loss:  0.051764100790023804\n",
      "saved model at epoch:  18 test_loss:  0.0508277527987957\n",
      "saved model at epoch:  19 test_loss:  0.04979243874549866\n",
      "saved model at epoch:  20 test_loss:  0.048649922013282776\n",
      "saved model at epoch:  21 test_loss:  0.04739319533109665\n",
      "saved model at epoch:  22 test_loss:  0.04601722210645676\n",
      "saved model at epoch:  23 test_loss:  0.04451986774802208\n",
      "saved model at epoch:  24 test_loss:  0.04290303587913513\n",
      "saved model at epoch:  25 test_loss:  0.04117359220981598\n",
      "saved model at epoch:  26 test_loss:  0.03934411704540253\n",
      "saved model at epoch:  27 test_loss:  0.03743283450603485\n",
      "saved model at epoch:  28 test_loss:  0.03546237200498581\n",
      "saved model at epoch:  29 test_loss:  0.03345745429396629\n",
      "saved model at epoch:  30 test_loss:  0.03144127130508423\n",
      "saved model at epoch:  31 test_loss:  0.029431559145450592\n",
      "saved model at epoch:  32 test_loss:  0.027436990290880203\n",
      "saved model at epoch:  33 test_loss:  0.025455281138420105\n",
      "saved model at epoch:  34 test_loss:  0.023473775014281273\n",
      "saved model at epoch:  35 test_loss:  0.021473316475749016\n",
      "saved model at epoch:  36 test_loss:  0.019435856491327286\n",
      "saved model at epoch:  37 test_loss:  0.01735464483499527\n",
      "saved model at epoch:  38 test_loss:  0.015237854793667793\n",
      "saved model at epoch:  39 test_loss:  0.013095546513795853\n",
      "saved model at epoch:  40 test_loss:  0.010926456190645695\n",
      "saved model at epoch:  41 test_loss:  0.008741872385144234\n",
      "saved model at epoch:  42 test_loss:  0.0066206082701683044\n",
      "saved model at epoch:  43 test_loss:  0.004725269041955471\n",
      "saved model at epoch:  44 test_loss:  0.0032299968879669905\n",
      "saved model at epoch:  45 test_loss:  0.0022146704141050577\n",
      "saved model at epoch:  46 test_loss:  0.0016248133033514023\n",
      "saved model at epoch:  47 test_loss:  0.0013246142771095037\n",
      "saved model at epoch:  48 test_loss:  0.0011807556729763746\n",
      "saved model at epoch:  49 test_loss:  0.0011063115671277046\n",
      "saved model at epoch:  50 test_loss:  0.001058403868228197\n",
      "saved model at epoch:  51 test_loss:  0.00101980019826442\n",
      "saved model at epoch:  52 test_loss:  0.000984525540843606\n",
      "saved model at epoch:  53 test_loss:  0.0009506781934760511\n",
      "saved model at epoch:  54 test_loss:  0.0009176148450933397\n",
      "saved model at epoch:  55 test_loss:  0.0008850738522596657\n",
      "saved model at epoch:  56 test_loss:  0.0008529283222742379\n",
      "saved model at epoch:  57 test_loss:  0.0008211441454477608\n",
      "saved model at epoch:  58 test_loss:  0.0007897685864008963\n",
      "saved model at epoch:  59 test_loss:  0.0007589020533487201\n",
      "saved model at epoch:  60 test_loss:  0.0007286740001291037\n",
      "saved model at epoch:  61 test_loss:  0.0006992225535213947\n",
      "saved model at epoch:  62 test_loss:  0.0006706637796014547\n",
      "saved model at epoch:  63 test_loss:  0.0006430852226912975\n",
      "saved model at epoch:  64 test_loss:  0.0006165534141473472\n",
      "saved model at epoch:  65 test_loss:  0.0005910904728807509\n",
      "saved model at epoch:  66 test_loss:  0.0005666950019076467\n",
      "saved model at epoch:  67 test_loss:  0.0005433411570265889\n",
      "saved model at epoch:  68 test_loss:  0.0005209734663367271\n",
      "saved model at epoch:  69 test_loss:  0.0004995521157979965\n",
      "saved model at epoch:  70 test_loss:  0.00047902888036333025\n",
      "saved model at epoch:  71 test_loss:  0.0004593629273585975\n",
      "saved model at epoch:  72 test_loss:  0.0004405264917295426\n",
      "saved model at epoch:  73 test_loss:  0.0004225008306093514\n",
      "saved model at epoch:  74 test_loss:  0.0004052662116009742\n",
      "saved model at epoch:  75 test_loss:  0.0003888073842972517\n",
      "saved model at epoch:  76 test_loss:  0.00037310822517611086\n",
      "saved model at epoch:  77 test_loss:  0.00035815220326185226\n",
      "saved model at epoch:  78 test_loss:  0.0003439154243096709\n",
      "saved model at epoch:  79 test_loss:  0.0003303678531665355\n",
      "saved model at epoch:  80 test_loss:  0.00031747668981552124\n",
      "saved model at epoch:  81 test_loss:  0.0003052131796721369\n",
      "saved model at epoch:  82 test_loss:  0.0002935383527074009\n",
      "saved model at epoch:  83 test_loss:  0.0002824174298439175\n",
      "saved model at epoch:  84 test_loss:  0.00027181461337022483\n",
      "saved model at epoch:  85 test_loss:  0.00026169270859099925\n",
      "saved model at epoch:  86 test_loss:  0.0002520190901122987\n",
      "saved model at epoch:  87 test_loss:  0.00024275915347971022\n",
      "saved model at epoch:  88 test_loss:  0.00023387843975797296\n",
      "saved model at epoch:  89 test_loss:  0.0002253433340229094\n",
      "saved model at epoch:  90 test_loss:  0.00021712457237299532\n",
      "saved model at epoch:  91 test_loss:  0.00020919197413604707\n",
      "saved model at epoch:  92 test_loss:  0.00020152618526481092\n",
      "saved model at epoch:  93 test_loss:  0.00019411137327551842\n",
      "saved model at epoch:  94 test_loss:  0.00018694368191063404\n",
      "saved model at epoch:  95 test_loss:  0.0001800295867724344\n",
      "saved model at epoch:  96 test_loss:  0.00017338665202260017\n",
      "saved model at epoch:  97 test_loss:  0.00016703028813935816\n",
      "saved model at epoch:  98 test_loss:  0.00016098670312203467\n",
      "saved model at epoch:  99 test_loss:  0.00015527017239946872\n",
      "saved model at epoch:  100 test_loss:  0.0001498856145190075\n",
      "saved model at epoch:  101 test_loss:  0.00014481494145002216\n",
      "saved model at epoch:  102 test_loss:  0.00014001743693370372\n",
      "saved model at epoch:  103 test_loss:  0.0001354403793811798\n",
      "saved model at epoch:  104 test_loss:  0.00013101210060995072\n",
      "saved model at epoch:  105 test_loss:  0.00012666609836742282\n",
      "saved model at epoch:  106 test_loss:  0.00012234161840751767\n",
      "saved model at epoch:  107 test_loss:  0.00011800311040133238\n",
      "saved model at epoch:  108 test_loss:  0.0001136250066338107\n",
      "saved model at epoch:  109 test_loss:  0.00010920280328718945\n",
      "saved model at epoch:  110 test_loss:  0.00010474963346496224\n",
      "saved model at epoch:  111 test_loss:  0.00010028979158960283\n",
      "saved model at epoch:  112 test_loss:  9.58724704105407e-05\n",
      "saved model at epoch:  113 test_loss:  9.15616619749926e-05\n",
      "saved model at epoch:  114 test_loss:  8.742904174141586e-05\n",
      "saved model at epoch:  115 test_loss:  8.355005411431193e-05\n",
      "saved model at epoch:  116 test_loss:  7.999118679435924e-05\n",
      "saved model at epoch:  117 test_loss:  7.68008321756497e-05\n",
      "saved model at epoch:  118 test_loss:  7.399811875075102e-05\n",
      "saved model at epoch:  119 test_loss:  7.156625360948965e-05\n",
      "saved model at epoch:  120 test_loss:  6.94581976858899e-05\n",
      "saved model at epoch:  121 test_loss:  6.760573160136119e-05\n",
      "saved model at epoch:  122 test_loss:  6.593617581529543e-05\n",
      "saved model at epoch:  123 test_loss:  6.438959098886698e-05\n",
      "saved model at epoch:  124 test_loss:  6.291236059041694e-05\n",
      "saved model at epoch:  125 test_loss:  6.145839870441705e-05\n",
      "saved model at epoch:  126 test_loss:  5.999064160278067e-05\n",
      "saved model at epoch:  127 test_loss:  5.8495857956586406e-05\n",
      "saved model at epoch:  128 test_loss:  5.6981207308126613e-05\n",
      "saved model at epoch:  129 test_loss:  5.5467677157139406e-05\n",
      "saved model at epoch:  130 test_loss:  5.3983898396836594e-05\n",
      "saved model at epoch:  131 test_loss:  5.2556708396878093e-05\n",
      "saved model at epoch:  132 test_loss:  5.1186358177801594e-05\n",
      "saved model at epoch:  133 test_loss:  4.982853351975791e-05\n",
      "saved model at epoch:  134 test_loss:  4.8431196773890406e-05\n",
      "saved model at epoch:  135 test_loss:  4.698468546848744e-05\n",
      "saved model at epoch:  136 test_loss:  4.553409598884173e-05\n",
      "saved model at epoch:  137 test_loss:  4.4181437260704115e-05\n",
      "saved model at epoch:  138 test_loss:  4.307548442739062e-05\n",
      "saved model at epoch:  139 test_loss:  4.235943197272718e-05\n",
      "saved model at epoch:  140 test_loss:  4.211386840324849e-05\n",
      "saved model at epoch:  143 test_loss:  4.201138290227391e-05\n",
      "saved model at epoch:  144 test_loss:  4.146001083427109e-05\n",
      "saved model at epoch:  145 test_loss:  4.090230504516512e-05\n",
      "saved model at epoch:  146 test_loss:  4.0501836338080466e-05\n",
      "saved model at epoch:  147 test_loss:  4.0280039684148505e-05\n",
      "saved model at epoch:  148 test_loss:  4.018335312139243e-05\n",
      "saved model at epoch:  149 test_loss:  4.016906314063817e-05\n",
      "saved model at epoch:  160 test_loss:  4.0019815060077235e-05\n",
      "saved model at epoch:  161 test_loss:  3.9655929867876694e-05\n",
      "saved model at epoch:  162 test_loss:  3.9259128243429586e-05\n",
      "saved model at epoch:  163 test_loss:  3.882674718624912e-05\n",
      "saved model at epoch:  164 test_loss:  3.837047188426368e-05\n",
      "saved model at epoch:  165 test_loss:  3.789352922467515e-05\n",
      "saved model at epoch:  166 test_loss:  3.7391822843346745e-05\n",
      "saved model at epoch:  167 test_loss:  3.687694334075786e-05\n",
      "saved model at epoch:  168 test_loss:  3.6344117688713595e-05\n",
      "saved model at epoch:  169 test_loss:  3.579818076104857e-05\n",
      "saved model at epoch:  170 test_loss:  3.524029307300225e-05\n",
      "saved model at epoch:  171 test_loss:  3.467158603598364e-05\n",
      "saved model at epoch:  172 test_loss:  3.4091495763277635e-05\n",
      "saved model at epoch:  173 test_loss:  3.350376937305555e-05\n",
      "saved model at epoch:  174 test_loss:  3.290615131845698e-05\n",
      "saved model at epoch:  175 test_loss:  3.230243601137772e-05\n",
      "saved model at epoch:  176 test_loss:  3.1695544748799875e-05\n",
      "saved model at epoch:  177 test_loss:  3.1078448955668136e-05\n",
      "saved model at epoch:  178 test_loss:  3.045798985112924e-05\n",
      "saved model at epoch:  179 test_loss:  2.9833729058736935e-05\n",
      "saved model at epoch:  180 test_loss:  2.920690894825384e-05\n",
      "saved model at epoch:  181 test_loss:  2.8576614568009973e-05\n",
      "saved model at epoch:  182 test_loss:  2.7948162824031897e-05\n",
      "saved model at epoch:  183 test_loss:  2.7317251806380227e-05\n",
      "saved model at epoch:  184 test_loss:  2.668828165042214e-05\n",
      "saved model at epoch:  185 test_loss:  2.6063273253384978e-05\n",
      "saved model at epoch:  186 test_loss:  2.5440462195547298e-05\n",
      "saved model at epoch:  187 test_loss:  2.482418858562596e-05\n",
      "saved model at epoch:  188 test_loss:  2.4216675228672102e-05\n",
      "saved model at epoch:  189 test_loss:  2.3618493287358433e-05\n",
      "saved model at epoch:  190 test_loss:  2.3032540411804803e-05\n",
      "saved model at epoch:  191 test_loss:  2.2460439140559174e-05\n",
      "saved model at epoch:  192 test_loss:  2.1904490495217033e-05\n",
      "saved model at epoch:  193 test_loss:  2.1363512132666074e-05\n",
      "saved model at epoch:  194 test_loss:  2.0842791855102405e-05\n",
      "saved model at epoch:  195 test_loss:  2.033910459431354e-05\n",
      "saved model at epoch:  196 test_loss:  1.985454946407117e-05\n",
      "saved model at epoch:  197 test_loss:  1.938941568369046e-05\n",
      "saved model at epoch:  198 test_loss:  1.8941394955618307e-05\n",
      "saved model at epoch:  199 test_loss:  1.8511913367547095e-05\n",
      "saved model at epoch:  200 test_loss:  1.8096772691933438e-05\n",
      "saved model at epoch:  201 test_loss:  1.769636946846731e-05\n",
      "saved model at epoch:  202 test_loss:  1.731101110635791e-05\n",
      "saved model at epoch:  203 test_loss:  1.6941157809924334e-05\n",
      "saved model at epoch:  204 test_loss:  1.6582531316089444e-05\n",
      "saved model at epoch:  205 test_loss:  1.6241261619143188e-05\n",
      "saved model at epoch:  206 test_loss:  1.5914440155029297e-05\n",
      "saved model at epoch:  207 test_loss:  1.5604198779328726e-05\n",
      "saved model at epoch:  208 test_loss:  1.5310870367102325e-05\n",
      "saved model at epoch:  209 test_loss:  1.5033276213216595e-05\n",
      "saved model at epoch:  210 test_loss:  1.4776740499655716e-05\n",
      "saved model at epoch:  211 test_loss:  1.453445202059811e-05\n",
      "saved model at epoch:  212 test_loss:  1.4311112863651942e-05\n",
      "saved model at epoch:  213 test_loss:  1.41038426590967e-05\n",
      "saved model at epoch:  214 test_loss:  1.3913194379711058e-05\n",
      "saved model at epoch:  215 test_loss:  1.3736844266531989e-05\n",
      "saved model at epoch:  216 test_loss:  1.3575016055256128e-05\n",
      "saved model at epoch:  217 test_loss:  1.3425054930849e-05\n",
      "saved model at epoch:  218 test_loss:  1.328727557847742e-05\n",
      "saved model at epoch:  219 test_loss:  1.3162000868760515e-05\n",
      "saved model at epoch:  220 test_loss:  1.3045223568042275e-05\n",
      "saved model at epoch:  221 test_loss:  1.2936760867887642e-05\n",
      "saved model at epoch:  222 test_loss:  1.2837004760513082e-05\n",
      "saved model at epoch:  223 test_loss:  1.2742345461447258e-05\n",
      "saved model at epoch:  224 test_loss:  1.2655378668569028e-05\n",
      "saved model at epoch:  225 test_loss:  1.257263920706464e-05\n",
      "saved model at epoch:  226 test_loss:  1.2493244867073372e-05\n",
      "saved model at epoch:  227 test_loss:  1.241891641257098e-05\n",
      "saved model at epoch:  228 test_loss:  1.2346520634309854e-05\n",
      "saved model at epoch:  229 test_loss:  1.2278488611627836e-05\n",
      "saved model at epoch:  230 test_loss:  1.2211245120852254e-05\n",
      "saved model at epoch:  231 test_loss:  1.2145340406277683e-05\n",
      "saved model at epoch:  232 test_loss:  1.2082425200787839e-05\n",
      "saved model at epoch:  233 test_loss:  1.2020045687677339e-05\n",
      "saved model at epoch:  234 test_loss:  1.1958126378885936e-05\n",
      "saved model at epoch:  235 test_loss:  1.189759586850414e-05\n",
      "saved model at epoch:  236 test_loss:  1.1837366400868632e-05\n",
      "saved model at epoch:  237 test_loss:  1.1778471161960624e-05\n",
      "saved model at epoch:  238 test_loss:  1.171916755993152e-05\n",
      "saved model at epoch:  239 test_loss:  1.1659993106150068e-05\n",
      "saved model at epoch:  240 test_loss:  1.1601129699556623e-05\n",
      "saved model at epoch:  241 test_loss:  1.1543143955350388e-05\n",
      "saved model at epoch:  242 test_loss:  1.1484881724754814e-05\n",
      "saved model at epoch:  243 test_loss:  1.1427140634623356e-05\n",
      "saved model at epoch:  244 test_loss:  1.136960054282099e-05\n",
      "saved model at epoch:  245 test_loss:  1.1311438356642611e-05\n",
      "saved model at epoch:  246 test_loss:  1.125448034144938e-05\n",
      "saved model at epoch:  247 test_loss:  1.1197885214642156e-05\n",
      "saved model at epoch:  248 test_loss:  1.1141859431518242e-05\n",
      "saved model at epoch:  249 test_loss:  1.1085410733358003e-05\n",
      "saved model at epoch:  250 test_loss:  1.1030038876924664e-05\n",
      "saved model at epoch:  251 test_loss:  1.0976425073749851e-05\n",
      "saved model at epoch:  252 test_loss:  1.0922789442702197e-05\n",
      "saved model at epoch:  253 test_loss:  1.0870551705011167e-05\n",
      "saved model at epoch:  254 test_loss:  1.081863865692867e-05\n",
      "saved model at epoch:  255 test_loss:  1.0768641004688106e-05\n",
      "saved model at epoch:  256 test_loss:  1.0719487363530789e-05\n",
      "saved model at epoch:  257 test_loss:  1.0672382813936565e-05\n",
      "saved model at epoch:  258 test_loss:  1.0626243238220923e-05\n",
      "saved model at epoch:  259 test_loss:  1.0582362847344484e-05\n",
      "saved model at epoch:  260 test_loss:  1.0539580216573086e-05\n",
      "saved model at epoch:  261 test_loss:  1.049872753355885e-05\n",
      "saved model at epoch:  262 test_loss:  1.0459656550665386e-05\n",
      "saved model at epoch:  263 test_loss:  1.0422479135741014e-05\n",
      "saved model at epoch:  264 test_loss:  1.0387334441475105e-05\n",
      "saved model at epoch:  265 test_loss:  1.035412151395576e-05\n",
      "saved model at epoch:  266 test_loss:  1.0322523849026766e-05\n",
      "saved model at epoch:  267 test_loss:  1.0292873412254266e-05\n",
      "saved model at epoch:  268 test_loss:  1.026448080665432e-05\n",
      "saved model at epoch:  269 test_loss:  1.0238090908387676e-05\n",
      "saved model at epoch:  270 test_loss:  1.0214082067250274e-05\n",
      "saved model at epoch:  271 test_loss:  1.0191525689151604e-05\n",
      "saved model at epoch:  272 test_loss:  1.0171261237701401e-05\n",
      "saved model at epoch:  273 test_loss:  1.015184898278676e-05\n",
      "saved model at epoch:  274 test_loss:  1.0134329386346508e-05\n",
      "saved model at epoch:  275 test_loss:  1.0118146747117862e-05\n",
      "saved model at epoch:  276 test_loss:  1.0103167369379662e-05\n",
      "saved model at epoch:  277 test_loss:  1.009015159070259e-05\n",
      "saved model at epoch:  278 test_loss:  1.007853734336095e-05\n",
      "saved model at epoch:  279 test_loss:  1.0067772564070765e-05\n",
      "saved model at epoch:  280 test_loss:  1.0057991858047899e-05\n",
      "saved model at epoch:  281 test_loss:  1.0048978765553329e-05\n",
      "saved model at epoch:  282 test_loss:  1.0041824680229183e-05\n",
      "saved model at epoch:  283 test_loss:  1.0034909792011604e-05\n",
      "saved model at epoch:  284 test_loss:  1.0028616088675335e-05\n",
      "saved model at epoch:  285 test_loss:  1.0023358299804386e-05\n",
      "saved model at epoch:  286 test_loss:  1.0018365173891652e-05\n",
      "saved model at epoch:  287 test_loss:  1.001462896965677e-05\n",
      "saved model at epoch:  288 test_loss:  1.0010840924223885e-05\n",
      "saved model at epoch:  289 test_loss:  1.0008076969825197e-05\n",
      "saved model at epoch:  290 test_loss:  1.0005171134253033e-05\n",
      "saved model at epoch:  291 test_loss:  1.0003012903325725e-05\n",
      "saved model at epoch:  292 test_loss:  1.0000991096603684e-05\n",
      "saved model at epoch:  293 test_loss:  9.999320354836527e-06\n",
      "saved model at epoch:  294 test_loss:  9.998346286010928e-06\n",
      "saved model at epoch:  295 test_loss:  9.99702388071455e-06\n",
      "saved model at epoch:  296 test_loss:  9.996350854635239e-06\n",
      "saved model at epoch:  297 test_loss:  9.995650543714873e-06\n",
      "saved model at epoch:  298 test_loss:  9.99497660814086e-06\n",
      "saved model at epoch:  299 test_loss:  9.993927051255014e-06\n",
      "saved model at epoch:  300 test_loss:  9.993495041271672e-06\n",
      "saved model at epoch:  301 test_loss:  9.992753803089727e-06\n",
      "saved model at epoch:  302 test_loss:  9.99219082586933e-06\n",
      "saved model at epoch:  303 test_loss:  9.991168553824537e-06\n",
      "saved model at epoch:  304 test_loss:  9.990478247345891e-06\n",
      "saved model at epoch:  305 test_loss:  9.989856152969878e-06\n",
      "saved model at epoch:  306 test_loss:  9.989204954763409e-06\n",
      "saved model at epoch:  307 test_loss:  9.988189049181528e-06\n",
      "saved model at epoch:  308 test_loss:  9.987355042540003e-06\n",
      "saved model at epoch:  309 test_loss:  9.986110853787977e-06\n",
      "saved model at epoch:  310 test_loss:  9.98534778773319e-06\n",
      "saved model at epoch:  311 test_loss:  9.984401003748644e-06\n",
      "saved model at epoch:  312 test_loss:  9.982852134271525e-06\n",
      "saved model at epoch:  313 test_loss:  9.981727998820134e-06\n",
      "saved model at epoch:  314 test_loss:  9.980307368095964e-06\n",
      "saved model at epoch:  315 test_loss:  9.97930965240812e-06\n",
      "saved model at epoch:  316 test_loss:  9.977678018913139e-06\n",
      "saved model at epoch:  317 test_loss:  9.976482942875009e-06\n",
      "saved model at epoch:  318 test_loss:  9.974737622542307e-06\n",
      "saved model at epoch:  319 test_loss:  9.973043233912904e-06\n",
      "saved model at epoch:  320 test_loss:  9.971641702577472e-06\n",
      "saved model at epoch:  321 test_loss:  9.969925486075226e-06\n",
      "saved model at epoch:  322 test_loss:  9.968314770958386e-06\n",
      "saved model at epoch:  323 test_loss:  9.966190191335045e-06\n",
      "saved model at epoch:  324 test_loss:  9.964698620024137e-06\n",
      "saved model at epoch:  325 test_loss:  9.962547665054444e-06\n",
      "saved model at epoch:  326 test_loss:  9.960858733393252e-06\n",
      "saved model at epoch:  327 test_loss:  9.958945156540722e-06\n",
      "saved model at epoch:  328 test_loss:  9.957368092727847e-06\n",
      "saved model at epoch:  329 test_loss:  9.954706001735758e-06\n",
      "saved model at epoch:  330 test_loss:  9.95279879134614e-06\n",
      "saved model at epoch:  331 test_loss:  9.950636012945324e-06\n",
      "saved model at epoch:  332 test_loss:  9.949041668733116e-06\n",
      "saved model at epoch:  333 test_loss:  9.946420505002607e-06\n",
      "saved model at epoch:  334 test_loss:  9.944124940375332e-06\n",
      "saved model at epoch:  335 test_loss:  9.941581993189175e-06\n",
      "saved model at epoch:  336 test_loss:  9.939238225342706e-06\n",
      "saved model at epoch:  337 test_loss:  9.93701905827038e-06\n",
      "saved model at epoch:  338 test_loss:  9.93348476185929e-06\n",
      "saved model at epoch:  339 test_loss:  9.931389286066405e-06\n",
      "saved model at epoch:  340 test_loss:  9.928730833053123e-06\n",
      "saved model at epoch:  341 test_loss:  9.925495760398917e-06\n",
      "saved model at epoch:  342 test_loss:  9.923248398990836e-06\n",
      "saved model at epoch:  343 test_loss:  9.920094271365087e-06\n",
      "saved model at epoch:  344 test_loss:  9.917301213135943e-06\n",
      "saved model at epoch:  345 test_loss:  9.913995199894998e-06\n",
      "saved model at epoch:  346 test_loss:  9.911012966767885e-06\n",
      "saved model at epoch:  347 test_loss:  9.907755156746134e-06\n",
      "saved model at epoch:  348 test_loss:  9.904848411679268e-06\n",
      "saved model at epoch:  349 test_loss:  9.9010176199954e-06\n",
      "saved model at epoch:  350 test_loss:  9.89748787105782e-06\n",
      "saved model at epoch:  351 test_loss:  9.893860806187149e-06\n",
      "saved model at epoch:  352 test_loss:  9.889990906231105e-06\n",
      "saved model at epoch:  353 test_loss:  9.886824955174234e-06\n",
      "saved model at epoch:  354 test_loss:  9.883148777589668e-06\n",
      "saved model at epoch:  355 test_loss:  9.879603567242157e-06\n",
      "saved model at epoch:  356 test_loss:  9.875933756120503e-06\n",
      "saved model at epoch:  357 test_loss:  9.871988368104212e-06\n",
      "saved model at epoch:  358 test_loss:  9.868258530332241e-06\n",
      "saved model at epoch:  359 test_loss:  9.864281310001388e-06\n",
      "saved model at epoch:  360 test_loss:  9.86041959549766e-06\n",
      "saved model at epoch:  361 test_loss:  9.856037650024518e-06\n",
      "saved model at epoch:  362 test_loss:  9.85186761681689e-06\n",
      "saved model at epoch:  363 test_loss:  9.848114132182673e-06\n",
      "saved model at epoch:  364 test_loss:  9.84350117505528e-06\n",
      "saved model at epoch:  365 test_loss:  9.839059202931821e-06\n",
      "saved model at epoch:  366 test_loss:  9.834951015363913e-06\n",
      "saved model at epoch:  367 test_loss:  9.830273484112695e-06\n",
      "saved model at epoch:  368 test_loss:  9.826389941736124e-06\n",
      "saved model at epoch:  369 test_loss:  9.82153505901806e-06\n",
      "saved model at epoch:  370 test_loss:  9.816591955313925e-06\n",
      "saved model at epoch:  371 test_loss:  9.81212633632822e-06\n",
      "saved model at epoch:  372 test_loss:  9.808367394725792e-06\n",
      "saved model at epoch:  373 test_loss:  9.80255390459206e-06\n",
      "saved model at epoch:  374 test_loss:  9.798053724807687e-06\n",
      "saved model at epoch:  375 test_loss:  9.793555364012718e-06\n",
      "saved model at epoch:  376 test_loss:  9.788743227545638e-06\n",
      "saved model at epoch:  377 test_loss:  9.78366551862564e-06\n",
      "saved model at epoch:  378 test_loss:  9.778473213373218e-06\n",
      "saved model at epoch:  379 test_loss:  9.773608326213434e-06\n",
      "saved model at epoch:  380 test_loss:  9.768644304131158e-06\n",
      "saved model at epoch:  381 test_loss:  9.763650268723723e-06\n",
      "saved model at epoch:  382 test_loss:  9.75860075413948e-06\n",
      "saved model at epoch:  383 test_loss:  9.753115591593087e-06\n",
      "saved model at epoch:  384 test_loss:  9.747649528435431e-06\n",
      "saved model at epoch:  385 test_loss:  9.742654583533294e-06\n",
      "saved model at epoch:  386 test_loss:  9.737037544255145e-06\n",
      "saved model at epoch:  387 test_loss:  9.73200803855434e-06\n",
      "saved model at epoch:  388 test_loss:  9.726938515086658e-06\n",
      "saved model at epoch:  389 test_loss:  9.721218702907208e-06\n",
      "saved model at epoch:  390 test_loss:  9.71582267084159e-06\n",
      "saved model at epoch:  391 test_loss:  9.710510312288534e-06\n",
      "saved model at epoch:  392 test_loss:  9.704199328552932e-06\n",
      "saved model at epoch:  393 test_loss:  9.699064321466722e-06\n",
      "saved model at epoch:  394 test_loss:  9.693673746369313e-06\n",
      "saved model at epoch:  395 test_loss:  9.688006684882566e-06\n",
      "saved model at epoch:  396 test_loss:  9.682203199190553e-06\n",
      "saved model at epoch:  397 test_loss:  9.676283298176713e-06\n",
      "saved model at epoch:  398 test_loss:  9.670933650340885e-06\n",
      "saved model at epoch:  399 test_loss:  9.664497156336438e-06\n",
      "saved model at epoch:  400 test_loss:  9.658679118729196e-06\n",
      "saved model at epoch:  401 test_loss:  9.653108463680837e-06\n",
      "saved model at epoch:  402 test_loss:  9.647527804190759e-06\n",
      "saved model at epoch:  403 test_loss:  9.641510587243829e-06\n",
      "saved model at epoch:  404 test_loss:  9.635387868911494e-06\n",
      "saved model at epoch:  405 test_loss:  9.62941976467846e-06\n",
      "saved model at epoch:  406 test_loss:  9.623416190152057e-06\n",
      "saved model at epoch:  407 test_loss:  9.617821888241451e-06\n",
      "saved model at epoch:  408 test_loss:  9.611611858417746e-06\n",
      "saved model at epoch:  409 test_loss:  9.605847480997909e-06\n",
      "saved model at epoch:  410 test_loss:  9.599494660506025e-06\n",
      "saved model at epoch:  411 test_loss:  9.593870345270261e-06\n",
      "saved model at epoch:  412 test_loss:  9.58685177465668e-06\n",
      "saved model at epoch:  413 test_loss:  9.5811165010673e-06\n",
      "saved model at epoch:  414 test_loss:  9.575069270795211e-06\n",
      "saved model at epoch:  415 test_loss:  9.568490895617288e-06\n",
      "saved model at epoch:  416 test_loss:  9.562554623698816e-06\n",
      "saved model at epoch:  417 test_loss:  9.555686119711027e-06\n",
      "saved model at epoch:  418 test_loss:  9.549878996040206e-06\n",
      "saved model at epoch:  419 test_loss:  9.54352526605362e-06\n",
      "saved model at epoch:  420 test_loss:  9.536869583826046e-06\n",
      "saved model at epoch:  421 test_loss:  9.530952411296312e-06\n",
      "saved model at epoch:  422 test_loss:  9.524224878987297e-06\n",
      "saved model at epoch:  423 test_loss:  9.518369552097283e-06\n",
      "saved model at epoch:  424 test_loss:  9.511266398476437e-06\n",
      "saved model at epoch:  425 test_loss:  9.505080925009679e-06\n",
      "saved model at epoch:  426 test_loss:  9.498192412138451e-06\n",
      "saved model at epoch:  427 test_loss:  9.492529898125213e-06\n",
      "saved model at epoch:  428 test_loss:  9.485581358603667e-06\n",
      "saved model at epoch:  429 test_loss:  9.479095751885325e-06\n",
      "saved model at epoch:  430 test_loss:  9.472762030782178e-06\n",
      "saved model at epoch:  431 test_loss:  9.466043593420181e-06\n",
      "saved model at epoch:  432 test_loss:  9.459854481974617e-06\n",
      "saved model at epoch:  433 test_loss:  9.4530232672696e-06\n",
      "saved model at epoch:  434 test_loss:  9.44621024245862e-06\n",
      "saved model at epoch:  435 test_loss:  9.439699169888627e-06\n",
      "saved model at epoch:  436 test_loss:  9.433138075110037e-06\n",
      "saved model at epoch:  437 test_loss:  9.426285032532178e-06\n",
      "saved model at epoch:  438 test_loss:  9.419389243703336e-06\n",
      "saved model at epoch:  439 test_loss:  9.412518920726143e-06\n",
      "saved model at epoch:  440 test_loss:  9.405769560544286e-06\n",
      "saved model at epoch:  441 test_loss:  9.399434020451736e-06\n",
      "saved model at epoch:  442 test_loss:  9.392453648615628e-06\n",
      "saved model at epoch:  443 test_loss:  9.386035344505217e-06\n",
      "saved model at epoch:  444 test_loss:  9.37937329581473e-06\n",
      "saved model at epoch:  445 test_loss:  9.372651220473927e-06\n",
      "saved model at epoch:  446 test_loss:  9.365564437757712e-06\n",
      "saved model at epoch:  447 test_loss:  9.358614988741465e-06\n",
      "saved model at epoch:  448 test_loss:  9.35210300667677e-06\n",
      "saved model at epoch:  449 test_loss:  9.345634680357762e-06\n",
      "saved model at epoch:  450 test_loss:  9.338620657217689e-06\n",
      "saved model at epoch:  451 test_loss:  9.331293767900206e-06\n",
      "saved model at epoch:  452 test_loss:  9.325101927970536e-06\n",
      "saved model at epoch:  453 test_loss:  9.317984222434461e-06\n",
      "saved model at epoch:  454 test_loss:  9.311077519669197e-06\n",
      "saved model at epoch:  455 test_loss:  9.303885235567577e-06\n",
      "saved model at epoch:  456 test_loss:  9.296952157455962e-06\n",
      "saved model at epoch:  457 test_loss:  9.289942681789398e-06\n",
      "saved model at epoch:  458 test_loss:  9.283202416554559e-06\n",
      "saved model at epoch:  459 test_loss:  9.276138371205889e-06\n",
      "saved model at epoch:  460 test_loss:  9.26910615817178e-06\n",
      "saved model at epoch:  461 test_loss:  9.262143976229709e-06\n",
      "saved model at epoch:  462 test_loss:  9.255350050807465e-06\n",
      "saved model at epoch:  463 test_loss:  9.24812502489658e-06\n",
      "saved model at epoch:  464 test_loss:  9.240970030077733e-06\n",
      "saved model at epoch:  465 test_loss:  9.233838682121132e-06\n",
      "saved model at epoch:  466 test_loss:  9.227135706169065e-06\n",
      "saved model at epoch:  467 test_loss:  9.219910680258181e-06\n",
      "saved model at epoch:  468 test_loss:  9.213120392814744e-06\n",
      "saved model at epoch:  469 test_loss:  9.206103641190566e-06\n",
      "saved model at epoch:  470 test_loss:  9.199101441481616e-06\n",
      "saved model at epoch:  471 test_loss:  9.191724529955536e-06\n",
      "saved model at epoch:  472 test_loss:  9.185287126456387e-06\n",
      "saved model at epoch:  473 test_loss:  9.178035725199152e-06\n",
      "saved model at epoch:  474 test_loss:  9.170918019663077e-06\n",
      "saved model at epoch:  475 test_loss:  9.16355293156812e-06\n",
      "saved model at epoch:  476 test_loss:  9.156670785159804e-06\n",
      "saved model at epoch:  477 test_loss:  9.149463949142955e-06\n",
      "saved model at epoch:  478 test_loss:  9.142020644503646e-06\n",
      "saved model at epoch:  479 test_loss:  9.135172149399295e-06\n",
      "saved model at epoch:  480 test_loss:  9.128072633757256e-06\n",
      "saved model at epoch:  481 test_loss:  9.120326467382256e-06\n",
      "saved model at epoch:  482 test_loss:  9.113732630794402e-06\n",
      "saved model at epoch:  483 test_loss:  9.106696779781487e-06\n",
      "saved model at epoch:  484 test_loss:  9.098357622860931e-06\n",
      "saved model at epoch:  485 test_loss:  9.091741958400235e-06\n",
      "saved model at epoch:  486 test_loss:  9.084850717044901e-06\n",
      "saved model at epoch:  487 test_loss:  9.077441973204259e-06\n",
      "saved model at epoch:  488 test_loss:  9.069852239917964e-06\n",
      "saved model at epoch:  489 test_loss:  9.063262041308917e-06\n",
      "saved model at epoch:  490 test_loss:  9.056099770532455e-06\n",
      "saved model at epoch:  491 test_loss:  9.048464562511072e-06\n",
      "saved model at epoch:  492 test_loss:  9.041406883625314e-06\n",
      "saved model at epoch:  493 test_loss:  9.03417185327271e-06\n",
      "saved model at epoch:  494 test_loss:  9.026533916767221e-06\n",
      "saved model at epoch:  495 test_loss:  9.019255230668932e-06\n",
      "saved model at epoch:  496 test_loss:  9.012263944896404e-06\n",
      "saved model at epoch:  497 test_loss:  9.004795174405444e-06\n",
      "saved model at epoch:  498 test_loss:  8.997758413897827e-06\n",
      "saved model at epoch:  499 test_loss:  8.990542482933961e-06\n",
      "saved model at epoch:  500 test_loss:  8.983058251033071e-06\n",
      "saved model at epoch:  501 test_loss:  8.975479431683198e-06\n",
      "saved model at epoch:  502 test_loss:  8.9682989710127e-06\n",
      "saved model at epoch:  503 test_loss:  8.96085566637339e-06\n",
      "saved model at epoch:  504 test_loss:  8.953553333412856e-06\n",
      "saved model at epoch:  505 test_loss:  8.94623008207418e-06\n",
      "saved model at epoch:  506 test_loss:  8.938869541452732e-06\n",
      "saved model at epoch:  507 test_loss:  8.93114793143468e-06\n",
      "saved model at epoch:  508 test_loss:  8.923978384700604e-06\n",
      "saved model at epoch:  509 test_loss:  8.917103514249902e-06\n",
      "saved model at epoch:  510 test_loss:  8.910004908102565e-06\n",
      "saved model at epoch:  511 test_loss:  8.90203045855742e-06\n",
      "saved model at epoch:  512 test_loss:  8.894648090063129e-06\n",
      "saved model at epoch:  513 test_loss:  8.887003787094727e-06\n",
      "saved model at epoch:  514 test_loss:  8.879538654582575e-06\n",
      "saved model at epoch:  515 test_loss:  8.872545549820643e-06\n",
      "saved model at epoch:  516 test_loss:  8.864672054187395e-06\n",
      "saved model at epoch:  517 test_loss:  8.857571629050653e-06\n",
      "saved model at epoch:  518 test_loss:  8.850000085658394e-06\n",
      "saved model at epoch:  519 test_loss:  8.842225724947639e-06\n",
      "saved model at epoch:  520 test_loss:  8.835470907797571e-06\n",
      "saved model at epoch:  521 test_loss:  8.82752920006169e-06\n",
      "saved model at epoch:  522 test_loss:  8.820084076432977e-06\n",
      "saved model at epoch:  523 test_loss:  8.812476153252646e-06\n",
      "saved model at epoch:  524 test_loss:  8.80552215676289e-06\n",
      "saved model at epoch:  525 test_loss:  8.797484042588621e-06\n",
      "saved model at epoch:  526 test_loss:  8.789935236563906e-06\n",
      "saved model at epoch:  527 test_loss:  8.782485565461684e-06\n",
      "saved model at epoch:  528 test_loss:  8.77534785104217e-06\n",
      "saved model at epoch:  529 test_loss:  8.767600775172468e-06\n",
      "saved model at epoch:  530 test_loss:  8.759961019677576e-06\n",
      "saved model at epoch:  531 test_loss:  8.75220666785026e-06\n",
      "saved model at epoch:  532 test_loss:  8.745010745769832e-06\n",
      "saved model at epoch:  533 test_loss:  8.736977179069072e-06\n",
      "saved model at epoch:  534 test_loss:  8.729752153158188e-06\n",
      "saved model at epoch:  535 test_loss:  8.722695383767132e-06\n",
      "saved model at epoch:  536 test_loss:  8.714518116903491e-06\n",
      "saved model at epoch:  537 test_loss:  8.706821063242387e-06\n",
      "saved model at epoch:  538 test_loss:  8.699892532604281e-06\n",
      "saved model at epoch:  539 test_loss:  8.692326446180232e-06\n",
      "saved model at epoch:  540 test_loss:  8.683931810082868e-06\n",
      "saved model at epoch:  541 test_loss:  8.676372999616433e-06\n",
      "saved model at epoch:  542 test_loss:  8.668853297422174e-06\n",
      "saved model at epoch:  543 test_loss:  8.661304491397459e-06\n",
      "saved model at epoch:  544 test_loss:  8.653711120132357e-06\n",
      "saved model at epoch:  545 test_loss:  8.646001333545428e-06\n",
      "saved model at epoch:  546 test_loss:  8.638237886771094e-06\n",
      "saved model at epoch:  547 test_loss:  8.630902812001295e-06\n",
      "saved model at epoch:  548 test_loss:  8.623298526799772e-06\n",
      "saved model at epoch:  549 test_loss:  8.615554179414175e-06\n",
      "saved model at epoch:  550 test_loss:  8.607456948084291e-06\n",
      "saved model at epoch:  551 test_loss:  8.599768079875503e-06\n",
      "saved model at epoch:  552 test_loss:  8.592533049522899e-06\n",
      "saved model at epoch:  553 test_loss:  8.584785973653197e-06\n",
      "saved model at epoch:  554 test_loss:  8.57693339639809e-06\n",
      "saved model at epoch:  555 test_loss:  8.568908924644347e-06\n",
      "saved model at epoch:  556 test_loss:  8.561593858757988e-06\n",
      "saved model at epoch:  557 test_loss:  8.553108273190446e-06\n",
      "saved model at epoch:  558 test_loss:  8.54511290526716e-06\n",
      "saved model at epoch:  559 test_loss:  8.53808978718007e-06\n",
      "saved model at epoch:  560 test_loss:  8.529586921213195e-06\n",
      "saved model at epoch:  561 test_loss:  8.52216180646792e-06\n",
      "saved model at epoch:  562 test_loss:  8.514458386343904e-06\n",
      "saved model at epoch:  563 test_loss:  8.506560334353708e-06\n",
      "saved model at epoch:  564 test_loss:  8.498709576088004e-06\n",
      "saved model at epoch:  565 test_loss:  8.49162279337179e-06\n",
      "saved model at epoch:  566 test_loss:  8.48314903123537e-06\n",
      "saved model at epoch:  567 test_loss:  8.475301001453772e-06\n",
      "saved model at epoch:  568 test_loss:  8.467695806757547e-06\n",
      "saved model at epoch:  569 test_loss:  8.45968952489784e-06\n",
      "saved model at epoch:  570 test_loss:  8.452105248579755e-06\n",
      "saved model at epoch:  571 test_loss:  8.444014383712783e-06\n",
      "saved model at epoch:  572 test_loss:  8.436007192358375e-06\n",
      "saved model at epoch:  573 test_loss:  8.42805366119137e-06\n",
      "saved model at epoch:  574 test_loss:  8.420203812420368e-06\n",
      "saved model at epoch:  575 test_loss:  8.411942872044165e-06\n",
      "saved model at epoch:  576 test_loss:  8.404293112107553e-06\n",
      "saved model at epoch:  577 test_loss:  8.396411431021988e-06\n",
      "saved model at epoch:  578 test_loss:  8.38860978547018e-06\n",
      "saved model at epoch:  579 test_loss:  8.380274266528431e-06\n",
      "saved model at epoch:  580 test_loss:  8.372956472157966e-06\n",
      "saved model at epoch:  581 test_loss:  8.36412436910905e-06\n",
      "saved model at epoch:  582 test_loss:  8.3566092143883e-06\n",
      "saved model at epoch:  583 test_loss:  8.348594747076277e-06\n",
      "saved model at epoch:  584 test_loss:  8.340964086528402e-06\n",
      "saved model at epoch:  585 test_loss:  8.3328068285482e-06\n",
      "saved model at epoch:  586 test_loss:  8.324489499500487e-06\n",
      "saved model at epoch:  587 test_loss:  8.31658053357387e-06\n",
      "saved model at epoch:  588 test_loss:  8.308571523230057e-06\n",
      "saved model at epoch:  589 test_loss:  8.300722583953757e-06\n",
      "saved model at epoch:  590 test_loss:  8.292638085549697e-06\n",
      "saved model at epoch:  591 test_loss:  8.284717296191957e-06\n",
      "saved model at epoch:  592 test_loss:  8.276540938823018e-06\n",
      "saved model at epoch:  593 test_loss:  8.26814448373625e-06\n",
      "saved model at epoch:  594 test_loss:  8.26033101475332e-06\n",
      "saved model at epoch:  595 test_loss:  8.251983672380447e-06\n",
      "saved model at epoch:  596 test_loss:  8.243775482696947e-06\n",
      "saved model at epoch:  597 test_loss:  8.23601021693321e-06\n",
      "saved model at epoch:  598 test_loss:  8.227919352066237e-06\n",
      "saved model at epoch:  599 test_loss:  8.22017955215415e-06\n",
      "saved model at epoch:  600 test_loss:  8.211630301957484e-06\n",
      "saved model at epoch:  601 test_loss:  8.203413017326966e-06\n",
      "saved model at epoch:  602 test_loss:  8.1954276538454e-06\n",
      "saved model at epoch:  603 test_loss:  8.187163075490389e-06\n",
      "saved model at epoch:  604 test_loss:  8.179104952432681e-06\n",
      "saved model at epoch:  605 test_loss:  8.170711225830019e-06\n",
      "saved model at epoch:  606 test_loss:  8.162382073351182e-06\n",
      "saved model at epoch:  607 test_loss:  8.154397619364318e-06\n",
      "saved model at epoch:  608 test_loss:  8.146003892761655e-06\n",
      "saved model at epoch:  609 test_loss:  8.13772658148082e-06\n",
      "saved model at epoch:  610 test_loss:  8.130145943141542e-06\n",
      "saved model at epoch:  611 test_loss:  8.121753126033582e-06\n",
      "saved model at epoch:  612 test_loss:  8.11353402241366e-06\n",
      "saved model at epoch:  613 test_loss:  8.105378583422862e-06\n",
      "saved model at epoch:  614 test_loss:  8.09704670245992e-06\n",
      "saved model at epoch:  615 test_loss:  8.088637514447328e-06\n",
      "saved model at epoch:  616 test_loss:  8.080251973296981e-06\n",
      "saved model at epoch:  617 test_loss:  8.071668162301648e-06\n",
      "saved model at epoch:  618 test_loss:  8.063910172495525e-06\n",
      "saved model at epoch:  619 test_loss:  8.05521722213598e-06\n",
      "saved model at epoch:  620 test_loss:  8.047450137382839e-06\n",
      "saved model at epoch:  621 test_loss:  8.039492058742326e-06\n",
      "saved model at epoch:  622 test_loss:  8.030867320485413e-06\n",
      "saved model at epoch:  623 test_loss:  8.02232443675166e-06\n",
      "saved model at epoch:  624 test_loss:  8.014328159333672e-06\n",
      "saved model at epoch:  625 test_loss:  8.005876225070097e-06\n",
      "saved model at epoch:  626 test_loss:  7.99756253400119e-06\n",
      "saved model at epoch:  627 test_loss:  7.988953257154208e-06\n",
      "saved model at epoch:  628 test_loss:  7.980392183526419e-06\n",
      "saved model at epoch:  629 test_loss:  7.97231859905878e-06\n",
      "saved model at epoch:  630 test_loss:  7.96394124336075e-06\n",
      "saved model at epoch:  631 test_loss:  7.955703040352091e-06\n",
      "saved model at epoch:  632 test_loss:  7.947284757392481e-06\n",
      "saved model at epoch:  633 test_loss:  7.939052011352032e-06\n",
      "saved model at epoch:  634 test_loss:  7.930198080430273e-06\n",
      "saved model at epoch:  635 test_loss:  7.921994438220281e-06\n",
      "saved model at epoch:  636 test_loss:  7.913697118056007e-06\n",
      "saved model at epoch:  637 test_loss:  7.905349775683135e-06\n",
      "saved model at epoch:  638 test_loss:  7.896889655967243e-06\n",
      "saved model at epoch:  639 test_loss:  7.88853685662616e-06\n",
      "saved model at epoch:  640 test_loss:  7.879859367676545e-06\n",
      "saved model at epoch:  641 test_loss:  7.87135104474146e-06\n",
      "saved model at epoch:  642 test_loss:  7.863113751227502e-06\n",
      "saved model at epoch:  643 test_loss:  7.854543582652695e-06\n",
      "saved model at epoch:  644 test_loss:  7.845731488487218e-06\n",
      "saved model at epoch:  645 test_loss:  7.837388693587855e-06\n",
      "saved model at epoch:  646 test_loss:  7.82933784648776e-06\n",
      "saved model at epoch:  647 test_loss:  7.820504833944142e-06\n",
      "saved model at epoch:  648 test_loss:  7.812154763087165e-06\n",
      "saved model at epoch:  649 test_loss:  7.803808330208994e-06\n",
      "saved model at epoch:  650 test_loss:  7.795147212164011e-06\n",
      "saved model at epoch:  651 test_loss:  7.786838068568613e-06\n",
      "saved model at epoch:  652 test_loss:  7.778250619594473e-06\n",
      "saved model at epoch:  653 test_loss:  7.770336196699645e-06\n",
      "saved model at epoch:  654 test_loss:  7.761762390146032e-06\n",
      "saved model at epoch:  655 test_loss:  7.753282261546701e-06\n",
      "saved model at epoch:  656 test_loss:  7.744731192360632e-06\n",
      "saved model at epoch:  657 test_loss:  7.736938641755842e-06\n",
      "saved model at epoch:  658 test_loss:  7.72802741266787e-06\n",
      "saved model at epoch:  659 test_loss:  7.720195753790904e-06\n",
      "saved model at epoch:  660 test_loss:  7.711963007750455e-06\n",
      "saved model at epoch:  661 test_loss:  7.703569281147793e-06\n",
      "saved model at epoch:  662 test_loss:  7.695630301896017e-06\n",
      "saved model at epoch:  663 test_loss:  7.687515790166799e-06\n",
      "saved model at epoch:  664 test_loss:  7.679604095756076e-06\n",
      "saved model at epoch:  665 test_loss:  7.671291314181872e-06\n",
      "saved model at epoch:  666 test_loss:  7.663347787456587e-06\n",
      "saved model at epoch:  667 test_loss:  7.6550441008294e-06\n",
      "saved model at epoch:  668 test_loss:  7.646919584658463e-06\n",
      "saved model at epoch:  669 test_loss:  7.638878742000088e-06\n",
      "saved model at epoch:  670 test_loss:  7.631032531207893e-06\n",
      "saved model at epoch:  671 test_loss:  7.622901193826692e-06\n",
      "saved model at epoch:  672 test_loss:  7.614613423356786e-06\n",
      "saved model at epoch:  673 test_loss:  7.606150575156789e-06\n",
      "saved model at epoch:  674 test_loss:  7.598186130053364e-06\n",
      "saved model at epoch:  675 test_loss:  7.589532742713345e-06\n",
      "saved model at epoch:  676 test_loss:  7.581664704048308e-06\n",
      "saved model at epoch:  677 test_loss:  7.573067250632448e-06\n",
      "saved model at epoch:  678 test_loss:  7.564996849396266e-06\n",
      "saved model at epoch:  679 test_loss:  7.556233413197333e-06\n",
      "saved model at epoch:  680 test_loss:  7.548349913122365e-06\n",
      "saved model at epoch:  681 test_loss:  7.540114893345162e-06\n",
      "saved model at epoch:  682 test_loss:  7.532172276114579e-06\n",
      "saved model at epoch:  683 test_loss:  7.523565727751702e-06\n",
      "saved model at epoch:  684 test_loss:  7.5155812737648375e-06\n",
      "saved model at epoch:  685 test_loss:  7.5072343861393165e-06\n",
      "saved model at epoch:  686 test_loss:  7.4985068749811035e-06\n",
      "saved model at epoch:  687 test_loss:  7.4904437497025356e-06\n",
      "saved model at epoch:  688 test_loss:  7.481914053641958e-06\n",
      "saved model at epoch:  689 test_loss:  7.4738659350259695e-06\n",
      "saved model at epoch:  690 test_loss:  7.465931957995053e-06\n",
      "saved model at epoch:  691 test_loss:  7.457407718902687e-06\n",
      "saved model at epoch:  692 test_loss:  7.4491731538728345e-06\n",
      "saved model at epoch:  693 test_loss:  7.441165507771075e-06\n",
      "saved model at epoch:  694 test_loss:  7.432806796714431e-06\n",
      "saved model at epoch:  695 test_loss:  7.42470137993223e-06\n",
      "saved model at epoch:  696 test_loss:  7.416268090310041e-06\n",
      "saved model at epoch:  697 test_loss:  7.408435976685723e-06\n",
      "saved model at epoch:  698 test_loss:  7.399632977467263e-06\n",
      "saved model at epoch:  699 test_loss:  7.391577128146309e-06\n",
      "saved model at epoch:  700 test_loss:  7.3834657996485475e-06\n",
      "saved model at epoch:  701 test_loss:  7.375176664936589e-06\n",
      "saved model at epoch:  702 test_loss:  7.367043053818634e-06\n",
      "saved model at epoch:  703 test_loss:  7.358924449363258e-06\n",
      "saved model at epoch:  704 test_loss:  7.350664873229107e-06\n",
      "saved model at epoch:  705 test_loss:  7.342618573602522e-06\n",
      "saved model at epoch:  706 test_loss:  7.334510428336216e-06\n",
      "saved model at epoch:  707 test_loss:  7.326271315832855e-06\n",
      "saved model at epoch:  708 test_loss:  7.318140433199005e-06\n",
      "saved model at epoch:  709 test_loss:  7.309930879273452e-06\n",
      "saved model at epoch:  710 test_loss:  7.301746336452197e-06\n",
      "saved model at epoch:  711 test_loss:  7.29339626559522e-06\n",
      "saved model at epoch:  712 test_loss:  7.285285391844809e-06\n",
      "saved model at epoch:  713 test_loss:  7.277431905095e-06\n",
      "saved model at epoch:  714 test_loss:  7.268682111316593e-06\n",
      "saved model at epoch:  715 test_loss:  7.261020073201507e-06\n",
      "saved model at epoch:  716 test_loss:  7.252697287185583e-06\n",
      "saved model at epoch:  717 test_loss:  7.2450061452400405e-06\n",
      "saved model at epoch:  718 test_loss:  7.2365387495665345e-06\n",
      "saved model at epoch:  719 test_loss:  7.228442882478703e-06\n",
      "saved model at epoch:  720 test_loss:  7.221028226922499e-06\n",
      "saved model at epoch:  721 test_loss:  7.211252523120493e-06\n",
      "saved model at epoch:  722 test_loss:  7.203338100225665e-06\n",
      "saved model at epoch:  723 test_loss:  7.1953199949348345e-06\n",
      "saved model at epoch:  724 test_loss:  7.1878421294968575e-06\n",
      "saved model at epoch:  725 test_loss:  7.179693056968972e-06\n",
      "saved model at epoch:  726 test_loss:  7.171637662395369e-06\n",
      "saved model at epoch:  727 test_loss:  7.163725058489945e-06\n",
      "saved model at epoch:  728 test_loss:  7.15575606591301e-06\n",
      "saved model at epoch:  729 test_loss:  7.147993983380729e-06\n",
      "saved model at epoch:  730 test_loss:  7.139671197364805e-06\n",
      "saved model at epoch:  731 test_loss:  7.131785878300434e-06\n",
      "saved model at epoch:  732 test_loss:  7.123675914044725e-06\n",
      "saved model at epoch:  733 test_loss:  7.1158224272949155e-06\n",
      "saved model at epoch:  734 test_loss:  7.107977125997422e-06\n",
      "saved model at epoch:  735 test_loss:  7.09969117451692e-06\n",
      "saved model at epoch:  736 test_loss:  7.092744908732129e-06\n",
      "saved model at epoch:  737 test_loss:  7.0843448156665545e-06\n",
      "saved model at epoch:  738 test_loss:  7.076399924699217e-06\n",
      "saved model at epoch:  739 test_loss:  7.068118520692224e-06\n",
      "saved model at epoch:  740 test_loss:  7.0600644903606735e-06\n",
      "saved model at epoch:  741 test_loss:  7.052039109112229e-06\n",
      "saved model at epoch:  742 test_loss:  7.044201993267052e-06\n",
      "saved model at epoch:  743 test_loss:  7.036246643110644e-06\n",
      "saved model at epoch:  744 test_loss:  7.028088475635741e-06\n",
      "saved model at epoch:  745 test_loss:  7.020627435849747e-06\n",
      "saved model at epoch:  746 test_loss:  7.012577952991705e-06\n",
      "saved model at epoch:  747 test_loss:  7.004956842138199e-06\n",
      "saved model at epoch:  748 test_loss:  6.996931915637106e-06\n",
      "saved model at epoch:  749 test_loss:  6.989229405007791e-06\n",
      "saved model at epoch:  750 test_loss:  6.981304522923892e-06\n",
      "saved model at epoch:  751 test_loss:  6.973355539230397e-06\n",
      "saved model at epoch:  752 test_loss:  6.9657030508096796e-06\n",
      "saved model at epoch:  753 test_loss:  6.958112862776034e-06\n",
      "saved model at epoch:  754 test_loss:  6.9498860284511466e-06\n",
      "saved model at epoch:  755 test_loss:  6.942369964235695e-06\n",
      "saved model at epoch:  756 test_loss:  6.934645170986187e-06\n",
      "saved model at epoch:  757 test_loss:  6.927226877451176e-06\n",
      "saved model at epoch:  758 test_loss:  6.918760391272372e-06\n",
      "saved model at epoch:  759 test_loss:  6.91110062689404e-06\n",
      "saved model at epoch:  760 test_loss:  6.903575467731571e-06\n",
      "saved model at epoch:  761 test_loss:  6.895847491250606e-06\n",
      "saved model at epoch:  762 test_loss:  6.888273674121592e-06\n",
      "saved model at epoch:  763 test_loss:  6.880409273435362e-06\n",
      "saved model at epoch:  764 test_loss:  6.8725435085070785e-06\n",
      "saved model at epoch:  765 test_loss:  6.864872375444975e-06\n",
      "saved model at epoch:  766 test_loss:  6.8575877776311245e-06\n",
      "saved model at epoch:  767 test_loss:  6.8497811298584566e-06\n",
      "saved model at epoch:  768 test_loss:  6.841715730843134e-06\n",
      "saved model at epoch:  769 test_loss:  6.834469786554109e-06\n",
      "saved model at epoch:  770 test_loss:  6.826543540228158e-06\n",
      "saved model at epoch:  771 test_loss:  6.819150257797446e-06\n",
      "saved model at epoch:  772 test_loss:  6.811672392359469e-06\n",
      "saved model at epoch:  773 test_loss:  6.804184067732422e-06\n",
      "saved model at epoch:  774 test_loss:  6.796632987970952e-06\n",
      "saved model at epoch:  775 test_loss:  6.790133284084732e-06\n",
      "saved model at epoch:  776 test_loss:  6.7819273681379855e-06\n",
      "saved model at epoch:  777 test_loss:  6.774042958568316e-06\n",
      "saved model at epoch:  778 test_loss:  6.7665987444343045e-06\n",
      "saved model at epoch:  779 test_loss:  6.758813924534479e-06\n",
      "saved model at epoch:  780 test_loss:  6.7512587520468514e-06\n",
      "saved model at epoch:  781 test_loss:  6.744167421857128e-06\n",
      "saved model at epoch:  782 test_loss:  6.736882369295927e-06\n",
      "saved model at epoch:  783 test_loss:  6.729109827574575e-06\n",
      "saved model at epoch:  784 test_loss:  6.721674708387582e-06\n",
      "saved model at epoch:  785 test_loss:  6.713882612530142e-06\n",
      "saved model at epoch:  786 test_loss:  6.706796739308629e-06\n",
      "saved model at epoch:  787 test_loss:  6.69952805765206e-06\n",
      "saved model at epoch:  788 test_loss:  6.6917477852257434e-06\n",
      "saved model at epoch:  789 test_loss:  6.684521395072807e-06\n",
      "saved model at epoch:  790 test_loss:  6.677099463558989e-06\n",
      "saved model at epoch:  791 test_loss:  6.6701027208182495e-06\n",
      "saved model at epoch:  792 test_loss:  6.662459782091901e-06\n",
      "saved model at epoch:  793 test_loss:  6.655459856119705e-06\n",
      "saved model at epoch:  794 test_loss:  6.6487305048212875e-06\n",
      "saved model at epoch:  795 test_loss:  6.64123172100517e-06\n",
      "saved model at epoch:  796 test_loss:  6.633812063228106e-06\n",
      "saved model at epoch:  797 test_loss:  6.626515641983133e-06\n",
      "saved model at epoch:  798 test_loss:  6.619013674935559e-06\n",
      "saved model at epoch:  799 test_loss:  6.611942353629274e-06\n",
      "saved model at epoch:  800 test_loss:  6.605217095057014e-06\n",
      "saved model at epoch:  801 test_loss:  6.597014362341724e-06\n",
      "saved model at epoch:  802 test_loss:  6.589619260921609e-06\n",
      "saved model at epoch:  803 test_loss:  6.58296630717814e-06\n",
      "saved model at epoch:  804 test_loss:  6.57575401419308e-06\n",
      "saved model at epoch:  805 test_loss:  6.56850534141995e-06\n",
      "saved model at epoch:  806 test_loss:  6.561487225553719e-06\n",
      "saved model at epoch:  807 test_loss:  6.55413123240578e-06\n",
      "saved model at epoch:  808 test_loss:  6.54724181003985e-06\n",
      "saved model at epoch:  809 test_loss:  6.541195944009814e-06\n",
      "saved model at epoch:  810 test_loss:  6.532939096359769e-06\n",
      "saved model at epoch:  811 test_loss:  6.5260792325716466e-06\n",
      "saved model at epoch:  812 test_loss:  6.518746431538602e-06\n",
      "saved model at epoch:  813 test_loss:  6.511866558867041e-06\n",
      "saved model at epoch:  814 test_loss:  6.504882094304776e-06\n",
      "saved model at epoch:  815 test_loss:  6.497844424302457e-06\n",
      "saved model at epoch:  816 test_loss:  6.490815394499805e-06\n",
      "saved model at epoch:  817 test_loss:  6.483562174253166e-06\n",
      "saved model at epoch:  818 test_loss:  6.478248906205408e-06\n",
      "saved model at epoch:  819 test_loss:  6.469575964729302e-06\n",
      "saved model at epoch:  820 test_loss:  6.463048976002028e-06\n",
      "saved model at epoch:  821 test_loss:  6.456088158302009e-06\n",
      "saved model at epoch:  822 test_loss:  6.449072316172533e-06\n",
      "saved model at epoch:  823 test_loss:  6.442175617848989e-06\n",
      "saved model at epoch:  824 test_loss:  6.435183422581758e-06\n",
      "saved model at epoch:  825 test_loss:  6.428450888051884e-06\n",
      "saved model at epoch:  826 test_loss:  6.4213563746307045e-06\n",
      "saved model at epoch:  827 test_loss:  6.414573817892233e-06\n",
      "saved model at epoch:  828 test_loss:  6.407889486581553e-06\n",
      "saved model at epoch:  829 test_loss:  6.400894108082866e-06\n",
      "saved model at epoch:  830 test_loss:  6.393608600774314e-06\n",
      "saved model at epoch:  831 test_loss:  6.38662959318026e-06\n",
      "saved model at epoch:  832 test_loss:  6.38010442344239e-06\n",
      "saved model at epoch:  833 test_loss:  6.374183612933848e-06\n",
      "saved model at epoch:  834 test_loss:  6.3671081989014056e-06\n",
      "saved model at epoch:  835 test_loss:  6.360545739880763e-06\n",
      "saved model at epoch:  836 test_loss:  6.353516710078111e-06\n",
      "saved model at epoch:  837 test_loss:  6.3469174165220466e-06\n",
      "saved model at epoch:  838 test_loss:  6.340617801470216e-06\n",
      "saved model at epoch:  839 test_loss:  6.333510100375861e-06\n",
      "saved model at epoch:  840 test_loss:  6.3269148995459545e-06\n",
      "saved model at epoch:  841 test_loss:  6.319768544926774e-06\n",
      "saved model at epoch:  842 test_loss:  6.313555786618963e-06\n",
      "saved model at epoch:  843 test_loss:  6.3070488067751285e-06\n",
      "saved model at epoch:  844 test_loss:  6.300833319983212e-06\n",
      "saved model at epoch:  845 test_loss:  6.293664682743838e-06\n",
      "saved model at epoch:  846 test_loss:  6.286932148213964e-06\n",
      "saved model at epoch:  847 test_loss:  6.280511115619447e-06\n",
      "saved model at epoch:  848 test_loss:  6.273748113017064e-06\n",
      "saved model at epoch:  849 test_loss:  6.267394837777829e-06\n",
      "saved model at epoch:  850 test_loss:  6.261052931222366e-06\n",
      "saved model at epoch:  851 test_loss:  6.254377240111353e-06\n",
      "saved model at epoch:  852 test_loss:  6.24792255621287e-06\n",
      "saved model at epoch:  853 test_loss:  6.241545179364039e-06\n",
      "saved model at epoch:  854 test_loss:  6.234916327230167e-06\n",
      "saved model at epoch:  855 test_loss:  6.22873631073162e-06\n",
      "saved model at epoch:  856 test_loss:  6.222008323675254e-06\n",
      "saved model at epoch:  857 test_loss:  6.215789198904531e-06\n",
      "saved model at epoch:  858 test_loss:  6.209507773746736e-06\n",
      "saved model at epoch:  859 test_loss:  6.202488293638453e-06\n",
      "saved model at epoch:  860 test_loss:  6.19641832599882e-06\n",
      "saved model at epoch:  861 test_loss:  6.1901732806290966e-06\n",
      "saved model at epoch:  862 test_loss:  6.183831828820985e-06\n",
      "saved model at epoch:  863 test_loss:  6.177626801218139e-06\n",
      "saved model at epoch:  864 test_loss:  6.171554105094401e-06\n",
      "saved model at epoch:  865 test_loss:  6.164737442304613e-06\n",
      "saved model at epoch:  866 test_loss:  6.158367796160746e-06\n",
      "saved model at epoch:  867 test_loss:  6.152595233288594e-06\n",
      "saved model at epoch:  868 test_loss:  6.1459550124709494e-06\n",
      "saved model at epoch:  869 test_loss:  6.140134701126954e-06\n",
      "saved model at epoch:  870 test_loss:  6.133288934506709e-06\n",
      "saved model at epoch:  871 test_loss:  6.127440883574309e-06\n",
      "saved model at epoch:  872 test_loss:  6.121195838204585e-06\n",
      "saved model at epoch:  873 test_loss:  6.114746156526962e-06\n",
      "saved model at epoch:  874 test_loss:  6.108567049523117e-06\n",
      "saved model at epoch:  875 test_loss:  6.102588486101013e-06\n",
      "saved model at epoch:  876 test_loss:  6.096161087043583e-06\n",
      "saved model at epoch:  877 test_loss:  6.090102488087723e-06\n",
      "saved model at epoch:  878 test_loss:  6.083933840272948e-06\n",
      "saved model at epoch:  879 test_loss:  6.078093520045513e-06\n",
      "saved model at epoch:  880 test_loss:  6.0719926295860205e-06\n",
      "saved model at epoch:  881 test_loss:  6.065828074497404e-06\n",
      "saved model at epoch:  882 test_loss:  6.0595398281293456e-06\n",
      "saved model at epoch:  883 test_loss:  6.0537004173966125e-06\n",
      "saved model at epoch:  884 test_loss:  6.047535407560645e-06\n",
      "saved model at epoch:  885 test_loss:  6.041451342753135e-06\n",
      "saved model at epoch:  886 test_loss:  6.035413207428064e-06\n",
      "saved model at epoch:  887 test_loss:  6.029336873325519e-06\n",
      "saved model at epoch:  888 test_loss:  6.023677087796386e-06\n",
      "saved model at epoch:  889 test_loss:  6.01746660322533e-06\n",
      "saved model at epoch:  890 test_loss:  6.01150577494991e-06\n",
      "saved model at epoch:  891 test_loss:  6.0056722759327386e-06\n",
      "saved model at epoch:  892 test_loss:  5.999502263875911e-06\n",
      "saved model at epoch:  893 test_loss:  5.9939611674053594e-06\n",
      "saved model at epoch:  894 test_loss:  5.9877406783925835e-06\n",
      "saved model at epoch:  895 test_loss:  5.981930371490307e-06\n",
      "saved model at epoch:  896 test_loss:  5.976021839160239e-06\n",
      "saved model at epoch:  897 test_loss:  5.969700396235567e-06\n",
      "saved model at epoch:  898 test_loss:  5.963781404716428e-06\n",
      "saved model at epoch:  899 test_loss:  5.9580652305157855e-06\n",
      "saved model at epoch:  900 test_loss:  5.95226038058172e-06\n",
      "saved model at epoch:  901 test_loss:  5.94642779105925e-06\n",
      "saved model at epoch:  902 test_loss:  5.9406220316304825e-06\n",
      "saved model at epoch:  903 test_loss:  5.934768978477223e-06\n",
      "saved model at epoch:  904 test_loss:  5.929136023041792e-06\n",
      "saved model at epoch:  905 test_loss:  5.923336630075937e-06\n",
      "saved model at epoch:  906 test_loss:  5.917681392020313e-06\n",
      "saved model at epoch:  907 test_loss:  5.9117355704074726e-06\n",
      "saved model at epoch:  908 test_loss:  5.9059002524008974e-06\n",
      "saved model at epoch:  909 test_loss:  5.899965799471829e-06\n",
      "saved model at epoch:  910 test_loss:  5.894243258808274e-06\n",
      "saved model at epoch:  911 test_loss:  5.888752639293671e-06\n",
      "saved model at epoch:  912 test_loss:  5.88292459724471e-06\n",
      "saved model at epoch:  913 test_loss:  5.877268449694384e-06\n",
      "saved model at epoch:  914 test_loss:  5.871730991202639e-06\n",
      "saved model at epoch:  915 test_loss:  5.865838375029853e-06\n",
      "saved model at epoch:  916 test_loss:  5.860129931534175e-06\n",
      "saved model at epoch:  917 test_loss:  5.854500614077551e-06\n",
      "saved model at epoch:  918 test_loss:  5.848951332154684e-06\n",
      "saved model at epoch:  919 test_loss:  5.843585768161574e-06\n",
      "saved model at epoch:  920 test_loss:  5.837910521222511e-06\n",
      "saved model at epoch:  921 test_loss:  5.831960152136162e-06\n",
      "saved model at epoch:  922 test_loss:  5.826632332173176e-06\n",
      "saved model at epoch:  923 test_loss:  5.82095026402385e-06\n",
      "saved model at epoch:  924 test_loss:  5.815276381326839e-06\n",
      "saved model at epoch:  925 test_loss:  5.809828053315869e-06\n",
      "saved model at epoch:  926 test_loss:  5.804404281661846e-06\n",
      "saved model at epoch:  927 test_loss:  5.798643996968167e-06\n",
      "saved model at epoch:  928 test_loss:  5.793052423541667e-06\n",
      "saved model at epoch:  929 test_loss:  5.7877709878084715e-06\n",
      "saved model at epoch:  930 test_loss:  5.7821316659101285e-06\n",
      "saved model at epoch:  931 test_loss:  5.7764723351283465e-06\n",
      "saved model at epoch:  932 test_loss:  5.771204541815678e-06\n",
      "saved model at epoch:  933 test_loss:  5.765827154391445e-06\n",
      "saved model at epoch:  934 test_loss:  5.760167368862312e-06\n",
      "saved model at epoch:  935 test_loss:  5.754913672717521e-06\n",
      "saved model at epoch:  936 test_loss:  5.7491956795274746e-06\n",
      "saved model at epoch:  937 test_loss:  5.743929705204209e-06\n",
      "saved model at epoch:  938 test_loss:  5.738266281696269e-06\n",
      "saved model at epoch:  939 test_loss:  5.7333591030328535e-06\n",
      "saved model at epoch:  940 test_loss:  5.727794359700056e-06\n",
      "saved model at epoch:  941 test_loss:  5.72242561247549e-06\n",
      "saved model at epoch:  942 test_loss:  5.716791747545358e-06\n",
      "saved model at epoch:  943 test_loss:  5.711393441742985e-06\n",
      "saved model at epoch:  944 test_loss:  5.706068350264104e-06\n",
      "saved model at epoch:  945 test_loss:  5.700975179934176e-06\n",
      "saved model at epoch:  946 test_loss:  5.69547819395666e-06\n",
      "saved model at epoch:  947 test_loss:  5.690242232958553e-06\n",
      "saved model at epoch:  948 test_loss:  5.6847743508114945e-06\n",
      "saved model at epoch:  949 test_loss:  5.679753030563006e-06\n",
      "saved model at epoch:  950 test_loss:  5.674658041243674e-06\n",
      "saved model at epoch:  951 test_loss:  5.669134679919807e-06\n",
      "saved model at epoch:  952 test_loss:  5.663869615091244e-06\n",
      "saved model at epoch:  953 test_loss:  5.6585995480418205e-06\n",
      "saved model at epoch:  954 test_loss:  5.653283551509958e-06\n",
      "saved model at epoch:  955 test_loss:  5.647723355650669e-06\n",
      "saved model at epoch:  956 test_loss:  5.642632913804846e-06\n",
      "saved model at epoch:  957 test_loss:  5.6374155974481255e-06\n",
      "saved model at epoch:  958 test_loss:  5.632664851873415e-06\n",
      "saved model at epoch:  959 test_loss:  5.627344307868043e-06\n",
      "saved model at epoch:  960 test_loss:  5.621983746095793e-06\n",
      "saved model at epoch:  961 test_loss:  5.6167918955907226e-06\n",
      "saved model at epoch:  962 test_loss:  5.611582764686318e-06\n",
      "saved model at epoch:  963 test_loss:  5.606435024674283e-06\n",
      "saved model at epoch:  964 test_loss:  5.6011754168139305e-06\n",
      "saved model at epoch:  965 test_loss:  5.596197752311127e-06\n",
      "saved model at epoch:  966 test_loss:  5.590887212747475e-06\n",
      "saved model at epoch:  967 test_loss:  5.586202860285994e-06\n",
      "saved model at epoch:  968 test_loss:  5.58091187485843e-06\n",
      "saved model at epoch:  969 test_loss:  5.575765044341097e-06\n",
      "saved model at epoch:  970 test_loss:  5.5706227612972725e-06\n",
      "saved model at epoch:  971 test_loss:  5.565372248383937e-06\n",
      "saved model at epoch:  972 test_loss:  5.5605773923161905e-06\n",
      "saved model at epoch:  973 test_loss:  5.555380994337611e-06\n",
      "saved model at epoch:  974 test_loss:  5.550354217120912e-06\n",
      "saved model at epoch:  975 test_loss:  5.545195108425105e-06\n",
      "saved model at epoch:  976 test_loss:  5.540327947528567e-06\n",
      "saved model at epoch:  977 test_loss:  5.535372565645957e-06\n",
      "saved model at epoch:  978 test_loss:  5.530333964998135e-06\n",
      "saved model at epoch:  979 test_loss:  5.525228516489733e-06\n",
      "saved model at epoch:  980 test_loss:  5.519984824786661e-06\n",
      "saved model at epoch:  981 test_loss:  5.515095836017281e-06\n",
      "saved model at epoch:  982 test_loss:  5.510225946636638e-06\n",
      "saved model at epoch:  983 test_loss:  5.505058197741164e-06\n",
      "saved model at epoch:  984 test_loss:  5.499931830854621e-06\n",
      "saved model at epoch:  985 test_loss:  5.49518608750077e-06\n",
      "saved model at epoch:  986 test_loss:  5.490216608450282e-06\n",
      "saved model at epoch:  987 test_loss:  5.485343081090832e-06\n",
      "saved model at epoch:  988 test_loss:  5.480028903548373e-06\n",
      "saved model at epoch:  989 test_loss:  5.475300895341206e-06\n",
      "saved model at epoch:  990 test_loss:  5.470548785524443e-06\n",
      "saved model at epoch:  991 test_loss:  5.465660251502413e-06\n",
      "saved model at epoch:  992 test_loss:  5.460904048959492e-06\n",
      "saved model at epoch:  993 test_loss:  5.455601694848156e-06\n",
      "saved model at epoch:  994 test_loss:  5.450988737720763e-06\n",
      "saved model at epoch:  995 test_loss:  5.446162958833156e-06\n",
      "saved model at epoch:  996 test_loss:  5.4410188567999285e-06\n",
      "saved model at epoch:  997 test_loss:  5.436470473796362e-06\n",
      "saved model at epoch:  998 test_loss:  5.431331373983994e-06\n",
      "saved model at epoch:  999 test_loss:  5.426608822745038e-06\n"
     ]
    }
   ],
   "source": [
    "# create a NN, all FCs, 1 input, 2 output, layer nodes is (1,4,4,2), using tanh() as activation function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def calculate_error(orig_lines, nn_lines):\n",
    "    # python version of average relative error between two sets of complex numbers\n",
    "    abs_error = 0\n",
    "    for i in range(len(orig_lines)):\n",
    "        orig_real, orig_imag = orig_lines[i]\n",
    "        nn_real, nn_imag = nn_lines[i]\n",
    "\n",
    "        diff_real = orig_real - nn_real\n",
    "        diff_imag = orig_imag - nn_imag\n",
    "\n",
    "        nominator = math.sqrt(diff_real * diff_real + diff_imag * diff_imag)\n",
    "        denominator = math.sqrt(orig_real * orig_real + orig_imag * orig_imag)\n",
    "\n",
    "        if denominator == 0 or math.isnan(nominator) or math.isnan(denominator):\n",
    "            e = 1.0\n",
    "        else:\n",
    "            e = min(nominator / denominator, 1.0)\n",
    "\n",
    "        abs_error += e\n",
    "\n",
    "    return abs_error / float(len(orig_lines))\n",
    "\n",
    "class dianet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dianet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 2)\n",
    "        self.fc2 = nn.Linear(2, 3)\n",
    "        self.fc3 = nn.Linear(3, 4)\n",
    "        self.fc4 = nn.Linear(4, 3)\n",
    "        self.fc5 = nn.Linear(3, 2)\n",
    "\n",
    "        self.msk2 = np.array([[1,0],[1,1],[0,1]])\n",
    "        self.msk3 = np.array([[1,0,0],[1,1,0],[0,1,1],[0,0,1]])\n",
    "        self.msk4 = np.array([[1,1,0,0],[0,1,1,0],[0,0,1,1]])\n",
    "        self.msk5 = np.array([[1,1,0],[0,1,1]])\n",
    "\n",
    "    def forward(self, x, dwn=-1, up=1):\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data, dwn, up)\n",
    "        self.fc1.bias.data = torch.clamp(self.fc1.bias.data, dwn, up)\n",
    "        x1 = torch.tanh(self.fc1(x))\n",
    "        # x1 = F.leaky_relu(self.fc1(x), negative_slope=0.125)\n",
    "\n",
    "        self.fc2.weight.data *= torch.from_numpy(self.msk2).float()\n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data, dwn, up)\n",
    "        self.fc2.bias.data = torch.clamp(self.fc2.bias.data, dwn, up)\n",
    "        x2 = torch.tanh(self.fc2(x1))\n",
    "        # x2 = F.leaky_relu(self.fc2(x1), negative_slope=0.125)\n",
    "\n",
    "        self.fc3.weight.data *= torch.from_numpy(self.msk3).float()\n",
    "        self.fc3.weight.data = torch.clamp(self.fc3.weight.data, dwn, up)\n",
    "        self.fc3.bias.data = torch.clamp(self.fc3.bias.data, dwn, up)\n",
    "        x3 = torch.tanh(self.fc3(x2))\n",
    "        x3c = torch.cat((x3[:,0:1], x3[:,1:-1]+x1, x3[:,-1:]), 1) # (n, 4)\n",
    "\n",
    "        self.fc4.weight.data *= torch.from_numpy(self.msk4).float()\n",
    "        self.fc4.weight.data = torch.clamp(self.fc4.weight.data, dwn, up)\n",
    "        self.fc4.bias.data = torch.clamp(self.fc4.bias.data, dwn, up)\n",
    "        x4 = torch.tanh(self.fc4(x3c))\n",
    "        x4c = x4 + x2 # (n, 3)\n",
    "\n",
    "        self.fc5.weight.data *= torch.from_numpy(self.msk5).float()\n",
    "        self.fc5.weight.data = torch.clamp(self.fc5.weight.data, dwn, up)\n",
    "        self.fc5.bias.data = torch.clamp(self.fc5.bias.data, dwn, up)\n",
    "        x5 = self.fc5(x4c)\n",
    "        x5c = x5 + x3[:,1:-1] # (n, 2)\n",
    "\n",
    "        return x5c\n",
    "\n",
    "# train the NN\n",
    "import torch.optim as optim\n",
    "\n",
    "# model = baseline() # test_loss 0.0001585180580150336; error:  0.015001012789398081\n",
    "model = dianet() # test_loss 0.001; error:  0.0401\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "minloss = 999\n",
    "for epoch in range(1000):\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    batchsize = 16\n",
    "    for i in range(0, len(train_in), batchsize):\n",
    "        optimizer.zero_grad()\n",
    "        input = train_in[i:i+batchsize]\n",
    "        tar = train_target[i:i+batchsize]\n",
    "        output = model(input, -1000, 1000)\n",
    "        loss = loss_fn(output, tar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        count += 1\n",
    "    epoch_loss /= count\n",
    "    \n",
    "    # test the model\n",
    "    model.eval()\n",
    "    test_output = model(test_in, -1000, 1000)\n",
    "    test_loss = loss_fn(test_output, test_target).item()\n",
    "    if test_loss < minloss:\n",
    "        minloss = test_loss\n",
    "        torch.save(model.state_dict(), 'fftdata5/dianet-nolimit.pt')\n",
    "        print('saved model at epoch: ', epoch, 'test_loss: ', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss 5.426608822745038e-06\n",
      "error:  0.0027790435759565573\n"
     ]
    }
   ],
   "source": [
    "def calculate_error_rate(test_output, test_target):\n",
    "    # Calculate the absolute error\n",
    "    absolute_error = np.abs(test_output - test_target)\n",
    "\n",
    "    # Calculate the mean absolute percentage error\n",
    "    mape = np.mean(absolute_error / np.abs(test_target)) * 100\n",
    "\n",
    "    return mape\n",
    "\n",
    "model = dianet()\n",
    "model.load_state_dict(torch.load('fftdata5/dianet-nolimit.pt'))\n",
    "model.eval()\n",
    "test_output = model(test_in, -1000, 1000)\n",
    "test_loss = loss_fn(test_output, test_target).item()\n",
    "print('test_loss', test_loss)\n",
    "\n",
    "test_output_np = test_output.detach().numpy()\n",
    "test_target_np = test_target.detach().numpy()\n",
    "\n",
    "err = calculate_error(test_target_np, test_output_np)\n",
    "print('error: ', err)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
