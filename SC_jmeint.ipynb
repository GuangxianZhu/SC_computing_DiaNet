{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (1000, 18) target: (1000,)\n",
      "input: (1000, 18) target: (1000,)\n",
      "tensor([0.3729, 0.2780, 0.6589, 0.6045, 0.7331, 0.2824, 0.7268, 0.3357, 0.5670,\n",
      "        0.6465, 0.5714, 0.7991, 0.4459, 0.4848, 0.9892, 0.0454, 0.1613, 0.3421]) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "from dianet import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    input_data = []\n",
    "    target_data = []\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        # print(i, line)\n",
    "        if i % 2 == 0:  # Input data (rows 1, 3, 5, 7, ...)\n",
    "            input_data.append([float(x) for x in line.strip().split()])\n",
    "        else:          # Target data (rows 2, 4, 6, 8, ...)\n",
    "            target_data.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "    # Convert to NumPy arrays and reshape\n",
    "    input_array = np.array(input_data).reshape(-1, 18)\n",
    "    target_array = np.array(target_data).reshape(-1, 2)\n",
    "    \n",
    "    return input_array, target_array\n",
    "\n",
    "train_in, train_target = read_data('jmeintdata/aggregated_train.txt')\n",
    "train_target = np.argmax(train_target, axis=1)\n",
    "print(\"input:\", train_in.shape, \"target:\", train_target.shape)\n",
    "train_in, train_target = torch.from_numpy(train_in).float(), torch.from_numpy(train_target).long()\n",
    "\n",
    "test_in, test_target = read_data('jmeintdata/aggregated_test.txt')\n",
    "test_target = np.argmax(test_target, axis=1)\n",
    "print(\"input:\", test_in.shape, \"target:\", test_target.shape)\n",
    "test_in, test_target = torch.from_numpy(test_in).float(), torch.from_numpy(test_target).long()\n",
    "\n",
    "print(train_in[0], train_target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dianet20(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dianet20, self).__init__()\n",
    "        self.fc1, self.fc2, self.fc3, self.fc4 = nn.Linear(18,17), nn.Linear(17,16), nn.Linear(16,15), nn.Linear(15,14)\n",
    "        self.fc5, self.fc6, self.fc7, self.fc8 = nn.Linear(14,13), nn.Linear(13,12), nn.Linear(12,11), nn.Linear(11,10)\n",
    "        self.fc9, self.fc10, self.fc11, self.fc12 = nn.Linear(10,9), nn.Linear(9,8), nn.Linear(8,7), nn.Linear(7,6)\n",
    "        self.fc13, self.fc14, self.fc15, self.fc16 = nn.Linear(6,5), nn.Linear(5,4), nn.Linear(4,3), nn.Linear(3,2)\n",
    "\n",
    "        self.msk1, self.msk2, self.msk3, self.msk4 = make_mask(17,18).T, make_mask(16,17).T, make_mask(15,16).T, make_mask(14,15).T\n",
    "        self.msk5, self.msk6, self.msk7, self.msk8 = make_mask(13,14).T, make_mask(12,13).T, make_mask(11,12).T, make_mask(10,11).T\n",
    "        self.msk9, self.msk10, self.msk11, self.msk12 = make_mask(9,10).T, make_mask(8,9).T, make_mask(7,8).T, make_mask(6,7).T\n",
    "        self.msk13, self.msk14, self.msk15, self.msk16 = make_mask(5,6).T, make_mask(4,5).T, make_mask(3,4).T, make_mask(2,3).T\n",
    "\n",
    "    def forward(self, x, dwn, up):\n",
    "        self.fc1.weight.data *= torch.from_numpy(self.msk1).float()\n",
    "        self.fc1.weight.data = torch.clamp(self.fc1.weight.data, min=dwn, max=up)\n",
    "        self.fc1.bias.data = torch.clamp(self.fc1.bias.data, min=dwn, max=up)\n",
    "        x1 = F.leaky_relu(self.fc1(x), negative_slope=0.125) # x1: 17\n",
    "\n",
    "        self.fc2.weight.data *= torch.from_numpy(self.msk2).float()\n",
    "        self.fc2.weight.data = torch.clamp(self.fc2.weight.data, min=dwn, max=up)\n",
    "        self.fc2.bias.data = torch.clamp(self.fc2.bias.data, min=dwn, max=up)\n",
    "        x2 = F.leaky_relu((self.fc2(x1)), negative_slope=0.125) # x2: 16\n",
    "\n",
    "        self.fc3.weight.data *= torch.from_numpy(self.msk3).float()\n",
    "        self.fc3.weight.data = torch.clamp(self.fc3.weight.data, min=dwn, max=up)\n",
    "        self.fc3.bias.data = torch.clamp(self.fc3.bias.data, min=dwn, max=up)\n",
    "        x3 = F.leaky_relu((self.fc3(x2)), negative_slope=0.125) # x3: 15\n",
    "        x3 = x3+x1[:,1:-1]\n",
    "\n",
    "        self.fc4.weight.data *= torch.from_numpy(self.msk4).float()\n",
    "        self.fc4.weight.data = torch.clamp(self.fc4.weight.data, min=dwn, max=up)\n",
    "        self.fc4.bias.data = torch.clamp(self.fc4.bias.data, min=dwn, max=up)\n",
    "        x4 = F.leaky_relu((self.fc4(x3)), negative_slope=0.125) # x4: 14\n",
    "        x4 = x4+x2[:,1:-1]\n",
    "\n",
    "        self.fc5.weight.data *= torch.from_numpy(self.msk5).float()\n",
    "        self.fc5.weight.data = torch.clamp(self.fc5.weight.data, min=dwn, max=up)\n",
    "        self.fc5.bias.data = torch.clamp(self.fc5.bias.data, min=dwn, max=up)\n",
    "        x5 = F.leaky_relu((self.fc5(x4)), negative_slope=0.125) # x5: 13\n",
    "        x5 = x5+x3[:,1:-1]\n",
    "\n",
    "        self.fc6.weight.data *= torch.from_numpy(self.msk6).float()\n",
    "        self.fc6.weight.data = torch.clamp(self.fc6.weight.data, min=dwn, max=up)\n",
    "        self.fc6.bias.data = torch.clamp(self.fc6.bias.data, min=dwn, max=up)\n",
    "        x6 = F.leaky_relu((self.fc6(x5)), negative_slope=0.125) # x6: 12\n",
    "        x6 = x6+x4[:,1:-1]\n",
    "\n",
    "        self.fc7.weight.data *= torch.from_numpy(self.msk7).float()\n",
    "        self.fc7.weight.data = torch.clamp(self.fc7.weight.data, min=dwn, max=up)\n",
    "        self.fc7.bias.data = torch.clamp(self.fc7.bias.data, min=dwn, max=up)\n",
    "        x7 = F.leaky_relu((self.fc7(x6)), negative_slope=0.125) # x7: 11\n",
    "        x7 = x7+x5[:,1:-1]\n",
    "\n",
    "        self.fc8.weight.data *= torch.from_numpy(self.msk8).float()\n",
    "        self.fc8.weight.data = torch.clamp(self.fc8.weight.data, min=dwn, max=up)\n",
    "        self.fc8.bias.data = torch.clamp(self.fc8.bias.data, min=dwn, max=up)\n",
    "        x8 = F.leaky_relu((self.fc8(x7)), negative_slope=0.125) # x8: 10\n",
    "        x8 = x8+x6[:,1:-1]\n",
    "\n",
    "        self.fc9.weight.data *= torch.from_numpy(self.msk9).float()\n",
    "        self.fc9.weight.data = torch.clamp(self.fc9.weight.data, min=dwn, max=up)\n",
    "        self.fc9.bias.data = torch.clamp(self.fc9.bias.data, min=dwn, max=up)\n",
    "        x9 = F.leaky_relu((self.fc9(x8)), negative_slope=0.125) # x9: 9\n",
    "        x9 = x9+x7[:,1:-1]\n",
    "\n",
    "        self.fc10.weight.data *= torch.from_numpy(self.msk10).float()\n",
    "        self.fc10.weight.data = torch.clamp(self.fc10.weight.data, min=dwn, max=up)\n",
    "        self.fc10.bias.data = torch.clamp(self.fc10.bias.data, min=dwn, max=up)\n",
    "        x10 = F.leaky_relu((self.fc10(x9)), negative_slope=0.125) # x10: 8\n",
    "        x10 = x10+x8[:,1:-1]\n",
    "\n",
    "        self.fc11.weight.data *= torch.from_numpy(self.msk11).float()\n",
    "        self.fc11.weight.data = torch.clamp(self.fc11.weight.data, min=dwn, max=up)\n",
    "        self.fc11.bias.data = torch.clamp(self.fc11.bias.data, min=dwn, max=up)\n",
    "        x11 = F.leaky_relu((self.fc11(x10)), negative_slope=0.125) # x11: 7\n",
    "        x11 = x11+x9[:,1:-1]\n",
    "\n",
    "        self.fc12.weight.data *= torch.from_numpy(self.msk12).float()\n",
    "        self.fc12.weight.data = torch.clamp(self.fc12.weight.data, min=dwn, max=up)\n",
    "        self.fc12.bias.data = torch.clamp(self.fc12.bias.data, min=dwn, max=up)\n",
    "        x12 = F.leaky_relu((self.fc12(x11)), negative_slope=0.125) # x12: 6\n",
    "        x12 = x12+x10[:,1:-1]\n",
    "\n",
    "        self.fc13.weight.data *= torch.from_numpy(self.msk13).float()\n",
    "        self.fc13.weight.data = torch.clamp(self.fc13.weight.data, min=dwn, max=up)\n",
    "        self.fc13.bias.data = torch.clamp(self.fc13.bias.data, min=dwn, max=up)\n",
    "        x13 = F.leaky_relu((self.fc13(x12)), negative_slope=0.125) # x13: 5\n",
    "        x13 = x13+x11[:,1:-1]\n",
    "\n",
    "        self.fc14.weight.data *= torch.from_numpy(self.msk14).float()\n",
    "        self.fc14.weight.data = torch.clamp(self.fc14.weight.data, min=dwn, max=up)\n",
    "        self.fc14.bias.data = torch.clamp(self.fc14.bias.data, min=dwn, max=up)\n",
    "        x14 = F.leaky_relu((self.fc14(x13)), negative_slope=0.125) # x14: 4\n",
    "        x14 = x14+x12[:,1:-1]\n",
    "\n",
    "        self.fc15.weight.data *= torch.from_numpy(self.msk15).float()\n",
    "        self.fc15.weight.data = torch.clamp(self.fc15.weight.data, min=dwn, max=up)\n",
    "        self.fc15.bias.data = torch.clamp(self.fc15.bias.data, min=dwn, max=up)\n",
    "        x15 = F.leaky_relu((self.fc15(x14)), negative_slope=0.125) # x15: 3\n",
    "        x15 = x15+x13[:,1:-1]\n",
    "\n",
    "        self.fc16.weight.data *= torch.from_numpy(self.msk16).float()\n",
    "        self.fc16.weight.data = torch.clamp(self.fc16.weight.data, min=dwn, max=up)\n",
    "        self.fc16.bias.data = torch.clamp(self.fc16.bias.data, min=dwn, max=up)\n",
    "        x16 = (self.fc16(x15)) # x16: 2\n",
    "        x16 = x16+x14[:,1:-1]\n",
    "\n",
    "        return x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at: 1  CEloss 0.6066116094589233\n",
      "saved at: 3  CEloss 0.6066063642501831\n",
      "saved at: 4  CEloss 0.6065918803215027\n",
      "saved at: 5  CEloss 0.6065812706947327\n",
      "saved at: 6  CEloss 0.6065694093704224\n",
      "saved at: 7  CEloss 0.606560468673706\n",
      "saved at: 8  CEloss 0.606548011302948\n",
      "saved at: 9  CEloss 0.6065354943275452\n",
      "saved at: 10  CEloss 0.606512188911438\n",
      "saved at: 11  CEloss 0.6064926385879517\n",
      "saved at: 12  CEloss 0.6064756512641907\n",
      "saved at: 13  CEloss 0.6064572334289551\n",
      "saved at: 14  CEloss 0.6064394116401672\n",
      "saved at: 15  CEloss 0.6064161062240601\n",
      "saved at: 16  CEloss 0.6063955426216125\n",
      "saved at: 17  CEloss 0.6063697934150696\n",
      "saved at: 18  CEloss 0.6063430309295654\n",
      "saved at: 19  CEloss 0.6063051819801331\n",
      "saved at: 20  CEloss 0.6062652468681335\n",
      "saved at: 21  CEloss 0.6062349677085876\n",
      "saved at: 22  CEloss 0.6062089204788208\n",
      "saved at: 23  CEloss 0.6061959862709045\n"
     ]
    }
   ],
   "source": [
    "model = dianet20() # \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "min_loss = 100\n",
    "for epoch in range(1,101):\n",
    "    runloss = 0.0\n",
    "    bs = 4\n",
    "    count = 0\n",
    "    for i in range(0, train_in.shape[0], bs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_in[i:i+bs], -1, 1)\n",
    "        loss = criterion(outputs, train_target[i:i+bs])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runloss += loss.item()\n",
    "        count += 1\n",
    "    runloss = runloss / count\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out = model(test_in, -1, 1)\n",
    "        test_loss = criterion(test_out, test_target)\n",
    "        if test_loss < min_loss:\n",
    "            min_loss = test_loss\n",
    "            torch.save(model.state_dict(), 'jmeintdata/dianet-11.pth')\n",
    "            print('saved at:', epoch, ' CEloss', test_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test: 70 %\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model = dianet20()\n",
    "\n",
    "model.load_state_dict(torch.load('jmeintdata/dianet-11.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_in, -1, 1)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Accuracy of test: %d %%' % (100 * torch.sum(test_target==predicted) / test_target.shape[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clamp 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved at: 1  CEloss 0.6069663166999817\n",
      "saved at: 2  CEloss 0.6068564057350159\n",
      "saved at: 3  CEloss 0.6067605018615723\n",
      "saved at: 4  CEloss 0.6066510081291199\n",
      "saved at: 5  CEloss 0.6066004633903503\n",
      "saved at: 6  CEloss 0.6065590381622314\n",
      "saved at: 7  CEloss 0.6065300107002258\n",
      "saved at: 8  CEloss 0.6065129041671753\n",
      "saved at: 9  CEloss 0.6064874529838562\n",
      "saved at: 10  CEloss 0.6064867973327637\n",
      "saved at: 11  CEloss 0.6064832210540771\n",
      "saved at: 14  CEloss 0.6064813733100891\n"
     ]
    }
   ],
   "source": [
    "model = dianet20() # \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "min_loss = 100\n",
    "for epoch in range(1,101):\n",
    "    runloss = 0.0\n",
    "    bs = 4\n",
    "    count = 0\n",
    "    for i in range(0, train_in.shape[0], bs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_in[i:i+bs], 0, 1)\n",
    "        loss = criterion(outputs, train_target[i:i+bs])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runloss += loss.item()\n",
    "        count += 1\n",
    "    runloss = runloss / count\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out = model(test_in, 0, 1)\n",
    "        test_loss = criterion(test_out, test_target)\n",
    "        if test_loss < min_loss:\n",
    "            min_loss = test_loss\n",
    "            torch.save(model.state_dict(), 'jmeintdata/dianet01.pth')\n",
    "            print('saved at:', epoch, ' CEloss', test_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test: 70 %\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "model = dianet20()\n",
    "\n",
    "model.load_state_dict(torch.load('jmeintdata/dianet01.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_in, 0, 1)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Accuracy of test: %d %%' % (100 * torch.sum(test_target==predicted) / test_target.shape[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaPy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
